---
layout: post
title: 
description: |
  CUDA와 CUDAExtension
hide_image: true
tags:
  - deeplearning
published: true
---

# CUDA
* * *

## 1. CUDA란?
Cuda는 NVIDIA에서 개발한 GPU 개발 툴. Cuda사용 목적은 **많은 양의 연산을 동시에 처리**하는 것으로 딥러닝이나 채굴에 사용된다.   
nvidia-driver,CUDA,CUDNN만 설치하면 딥러닝 개발 환경 구축이 가능하다. 
일단 c나 c++로 작성한 후 CUDA확장명(.cu)을 가진 C로 작성한다.   
그리고 CUDAExtension을 사용하면 GPU연산이 가능해진다. 

## 2. CUDAExtension
cuda지원 운영체제를 PyTorch와 병합한다. 
```py
from setuptools import setup
from torch.utils.cpp_extension import BuildExtension, CUDAExtension

setup(name='swin_window_process',
    ext_modules=[
        CUDAExtension('swin_window_process', [
            'swin_window_process.cpp',
            'swin_window_process_kernel.cu',
        ])
    ],
    cmdclass={'build_ext': BuildExtension})
```
swin_window_process는 cpp로 작성되어 있는 파일, swin_window_procesS_kernel.cu는 CUDA확장자 파일. 이 두개를 CUDAExtension하면 Pytorch에서 swin_window_process라는 
모듈로 import해와서 사용할 수 있게됨.

### 2.1. cpp파일
```cpp
#include <stdio.h>

void hello(void) {
	printf("Hello, World!\n");
}

int main(void) {
	hello();

	return 0;
}
```

### 2.2. cuda파일
2.1의 cpp를 cuda로 바꾸면...
```cu
#include <stdio.h>

__global__ void hello(void) {
	printf("Hello, CUDA! %d \n", threadIdx.x);
}

int main(void) {
	hello <<<1, 10>>> ();

	return 0;
}
```

#### 2.2.1. __global__
해당 함수를 GPU에서 돌아가도록 지정해줌. 이렇게 GPU에서 실행되는 함수를 **kernel(커널)** 이라고 부른다.

#### 2.2.2. <<<1,1>>>
<<<스레드 그룹의 갯수(block),각 스레드 그룹에서 몇개의 스레드를 실행할지>>>
<<<M , T >>> : M * T = 사용할 코어의 수
#### 2.2.3. 예시
```
#include <stdio.h>

__global__ void hello(void) {
	printf("Hello, CUDA! %d \n", threadIdx.x);
}

int main(void) {
	hello <<<1, 10>>> ();

	return 0;
}
```
<<<1,10>>> : 1개의 스레드 그룹이 있고 그 그룹 내에서 10개의 스레드 실행   
![image](https://user-images.githubusercontent.com/69246778/180418261-d294770b-534d-4591-a84f-6e5130ccf8fe.png)
   
<<<2,10>>> : 2개의 스레드 그룹이 있고 각 그룹 내에서 10개의 스레드를 실행   
![image](https://user-images.githubusercontent.com/69246778/180418276-0a378258-dfbf-46e7-ad20-3ee5d4d14359.png)

[참고](https://kingnamji.tistory.com/38)

## 3. CUDA thread
![image](https://user-images.githubusercontent.com/69246778/180419328-39301234-6889-46b6-80ad-d47db3f95f95.png)
* 가장 작은 각설탕 : Thread   
* 초록 격자 : Block
* 초롤 격자의 묶음 : Grid
[참고](https://velog.io/@aram_father/CUDA-Thread-Hierarchy)
