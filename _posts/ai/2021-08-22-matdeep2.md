---
layout: post
title: YOLOv2
description: |
  YOLOv2를 활용한 Multi object Detector
hide_image: true
tags:
  - ai
published: true
---


# Network training
* * *
trainig data의 라벨링이 끝났으면 이제 Network를 training해보자. **ResNet-50기반의 YOLOv2**를 이용한 Multi Object Detector를 구성할 계획이다.
[참고](https://kr.mathworks.com/help/vision/ug/create-yolo-v2-object-detection-network.html?searchHighlight=YOLO&s_tid=srchtitle)

# 1. Multi Object Detector 구성
매트랩 도움말에 나와있는 순서는 일단 다음과 같다.
![image](https://user-images.githubusercontent.com/69246778/130351314-b3cbe86b-d904-450e-9abd-0fa1e0a41ac4.png)

## 1.1. Load the pretrained network
미리 훈련된 네트워크를 먼저 load한다. (시간이 오래걸리니까 미리 되어있는거 걍 load하는 듯..?)   
ResNet-50기반의 YOLO를 사용할 거라서 **심층 신경망 디자이너 app -> ResNet-50설치**를 먼저 해준다
![image](https://user-images.githubusercontent.com/69246778/130351966-1f9f0a2b-e2d8-4c88-9482-6511d4a54959.png)
![image](https://user-images.githubusercontent.com/69246778/130352014-3b797bc0-6ce8-457d-9857-bf0e32ecfcbb.png)
   
![image](https://user-images.githubusercontent.com/69246778/130352170-b468d04b-04d2-439e-adba-25916f08ca76.png)
요렇게 되면 설치 완료된거   
   
![image](https://user-images.githubusercontent.com/69246778/130352345-eaa4ee07-2214-4d98-9583-8d681ad2712a.png)
심층 신경망 디자이너에서 열어보면 이렇게 생겼다.   
   
![image](https://user-images.githubusercontent.com/69246778/130352371-5ce2e639-5233-4806-a80a-58bc08ba973e.png)
![image](https://user-images.githubusercontent.com/69246778/130352380-b5ef61cc-aebd-4c8e-8d49-363da7a4eb30.png)
![image](https://user-images.githubusercontent.com/69246778/130352391-987eaa42-742c-4aad-ba3b-b8f455d8d25f.png)
![image](https://user-images.githubusercontent.com/69246778/130352396-85bb29a9-9b0e-495b-84ef-8aeeced8a741.png)
![image](https://user-images.githubusercontent.com/69246778/130352402-3565b617-0da2-4dbf-890f-8930ce470499.png)
![image](https://user-images.githubusercontent.com/69246778/130352408-cf9cb6e2-c6aa-4743-a896-831d64be8772.png)
pretrained layer의 파라미터는 이런것들이 있ㄷㅏ.

## 1.2. YOLO v2연걸하기
activation 40 layer에 YOLOv2를 연결해 Transfer learning을 구성하려고 한다.
 




## 1.3. Training
일단, training labeling 단계에서 완성했던 Image labeler를 mat file로 export한다. 파일명 training

data = load('groundTruth.mat');
trainingData = data.groundTruth;

rng(0);
shuffledIdx = randperm(height(trainingData));
idx = floor(0.8 * length(shuffledIdx) );

trainingIdx = 1:idx;
trainingDataTbl = trainingData(shuffledIdx(trainingIdx),:);

% validationIdx = idx+1 : idx + 1 + floor(0.2 * length(shuffledIdx) );
% validationDataTbl = trainingData(shuffledIdx(validationIdx),:);


imdsTrain = imageDatastore(trainingDataTbl{:,'imageFilename'});
bldsTrain = boxLabelDatastore(trainingDataTbl(:,'Car'));

% imdsValidation = imageDatastore(validationDataTbl{:,'imageFilename'});
% bldsValidation = boxLabelDatastore(validationDataTbl(:,'Car'));

training = combine(imdsTrain,bldsTrain);
% validation = combine(imdsValidation,bldsValidation);

net = load('yolov2VehicleDetector.mat');
lgraph = net.lgraph

lgraph.Layers

options = trainingOptions('sgdm',...
          'InitialLearnRate',0.001,...
          'Verbose',true,...
          'MiniBatchSize',16,...
          'MaxEpochs',30,...
          'Shuffle','never',...
          'VerboseFrequency',30,...
          'CheckpointPath',tempdir);

[detector,info] = trainYOLOv2ObjectDetector(training,lgraph,options);


net = load('yolov2VehicleDetector.mat');
lgraph = net.lgraph

inputSize = [224 224 3];
numClasses = 2;

trainingDataForEstimation = transform(trainingData,@(data)preprocessData(data,inputSize));
numAnchors = 1;
[anchorBoxes, meanIoU] = estimateAnchorBoxes(trainingData, numAnchors)

featureExtractionNetwork = resnet50;
featureLayer = 'activation_40_relu';
lgraph = yolov2Layers(inputSize,numClasses,anchorBoxes,featureExtractionNetwork,featureLayer);

augmentedTrainingData = transform(trainingData,@augmentData);
augmentedData = cell(4,1);
for k = 1:4
    data = read(augmentedTrainingData);
    augmentedData{k} = insertShape(data{1},'Rectangle',data{2});
    reset(augmentedTrainingData);
end
figure
montage(augmentedData,'BorderSize',10)

preprocessedTrainingData = transform(augmentedTrainingData,@(data)preprocessData(data,inputSize));
preprocessedValidationData = transform(validationData,@(data)preprocessData(data,inputSize));

data = read(preprocessedTrainingData);

I = data{1};
bbox = data{2};
annotatedImage = insertShape(I,'Rectangle',bbox);
annotatedImage = imresize(annotatedImage,2);
figure
imshow(annotatedImage)

options = trainingOptions('sgdm', ...
        'MiniBatchSize',16, ....
        'InitialLearnRate',1e-3, ...
        'MaxEpochs',20, ... 
        'CheckpointPath',tempdir, ...
        'ValidationData',preprocessedValidationData);
        
          

anchorBoxes = estimateAnchorBoxes(trainingData,numAnchors)
