---
layout: post
title: YOLOv2
description: |
  YOLOv2를 활용한 Multi object Detector
hide_image: true
tags:
  - ai
published: true
---


# Network training
* * *
trainig data의 라벨링이 끝났으면 이제 Network를 training해보자. **ResNet-50기반의 YOLOv2**를 이용한 Multi Object Detector를 구성할 계획이다.
[참고](https://kr.mathworks.com/help/vision/ug/create-yolo-v2-object-detection-network.html?searchHighlight=YOLO&s_tid=srchtitle)

# 1. Multi Object Detector 구성
매트랩 도움말에 나와있는 순서는 일단 다음과 같다.
![image](https://user-images.githubusercontent.com/69246778/130351314-b3cbe86b-d904-450e-9abd-0fa1e0a41ac4.png)

## 1.1. Load the pretrained network
미리 훈련된 네트워크를 먼저 load한다. (시간이 오래걸리니까 미리 되어있는거 걍 load하는 듯..?)   
ResNet-50기반의 YOLO를 사용할 거라서 **심층 신경망 디자이너 app -> ResNet-50설치**를 먼저 해준다
![image](https://user-images.githubusercontent.com/69246778/130351966-1f9f0a2b-e2d8-4c88-9482-6511d4a54959.png)
![image](https://user-images.githubusercontent.com/69246778/130352014-3b797bc0-6ce8-457d-9857-bf0e32ecfcbb.png)
   
![image](https://user-images.githubusercontent.com/69246778/130352170-b468d04b-04d2-439e-adba-25916f08ca76.png)
요렇게 되면 설치 완료된거   
   
![image](https://user-images.githubusercontent.com/69246778/130352345-eaa4ee07-2214-4d98-9583-8d681ad2712a.png)
심층 신경망 디자이너에서 열어보면 이렇게 생겼다.   
   
![image](https://user-images.githubusercontent.com/69246778/130438661-d841ac23-550c-4ebe-9e7d-90c64546bfe2.png)
확대해보면 이런데 여기 **activation_40 relu layer**에 YOLO를 연결할거

[참고영상](https://kr.mathworks.com/videos/object-detection-and-deep-learning-model-development-with-matlab-yolov2-1576477341892.html)

![image](https://user-images.githubusercontent.com/69246778/130440168-b39a10e9-e2bb-4423-950e-dc7ac8639973.png)
yolov2TransformLayer와 yolov2outlayer를 추가하고 연결해줬다. 이게 맞는진 몰겠음...

![image](https://user-images.githubusercontent.com/69246778/130440293-30a711c3-492c-4270-ba03-9546c738e8d1.png)
그리고나서 **내보내기 -> Code생성**




![image](https://user-images.githubusercontent.com/69246778/130352371-5ce2e639-5233-4806-a80a-58bc08ba973e.png)
![image](https://user-images.githubusercontent.com/69246778/130352380-b5ef61cc-aebd-4c8e-8d49-363da7a4eb30.png)
![image](https://user-images.githubusercontent.com/69246778/130352391-987eaa42-742c-4aad-ba3b-b8f455d8d25f.png)
![image](https://user-images.githubusercontent.com/69246778/130352396-85bb29a9-9b0e-495b-84ef-8aeeced8a741.png)
![image](https://user-images.githubusercontent.com/69246778/130352402-3565b617-0da2-4dbf-890f-8930ce470499.png)
![image](https://user-images.githubusercontent.com/69246778/130352408-cf9cb6e2-c6aa-4743-a896-831d64be8772.png)
pretrained layer의 파라미터는 이런것들이 있ㄷㅏ.

## 1.2. YOLO v2연걸하기
activation 40 layer에 YOLOv2를 연결해 Transfer learning을 구성하려고 한다.
 




## 1.3. Training

```
data = load('groundTruth.mat');
trainingData = data.groundTruth;

rng(0);
shuffledIdx = randperm(height(trainingData));
idx = floor(0.8 * length(shuffledIdx) );

trainingIdx = 1:idx;
trainingDataTbl = trainingData(shuffledIdx(trainingIdx),:);

validationIdx = idx+1 : idx + 1 + floor(0.2 * length(shuffledIdx) );
validationDataTbl = trainingData(shuffledIdx(validationIdx),:);


imdsTrain = imageDatastore(trainingDataTbl{:,'imageFilename'});
bldsTrain = boxLabelDatastore(trainingDataTbl(:,'Car'));

imdsValidation = imageDatastore(validationDataTbl{:,'imageFilename'});
bldsValidation = boxLabelDatastore(validationDataTbl(:,'Car'));

training = combine(imdsTrain,bldsTrain);
validation = combine(imdsValidation,bldsValidation);

inputSize = [227 227 3];
numClasses = width(trainingdata)-1;


trainingDataForEstimation = boxLabelDatastore(trainingdata(:,2:end))
numAnchors = 1;
[anchorBoxes, meanIoU] = estimateAnchorBoxes(trainingDataForEstimation, numAnchors)

featureExtractionNetwork = resnet50;
featureLayer = 'activation_40_relu';
lgraph = yolov2Layers(inputSize,numClasses,anchorBoxes,featureExtractionNetwork,featureLayer);


options = trainingOptions('sgdm', ...
        'MiniBatchSize',16, ....
        'InitialLearnRate',1e-3, ...
        'MaxEpochs',20, ... 
        'CheckpointPath',tempdir);

[detector,info] = trainYOLOv2ObjectDetector(trainingdata,lgraph,options);
```
   
![image](https://user-images.githubusercontent.com/69246778/130449646-5d35e328-abea-4e27-8d45-964f4af5beaf.png)
![image](https://user-images.githubusercontent.com/69246778/130463969-8a6d1742-58e8-44ae-b83a-6da2e68b84b7.png)
약 1시간 걸려서 training 끝.


![image](https://user-images.githubusercontent.com/69246778/130472940-491c8fb2-9b8a-47fc-9585-315950d2a246.png)

```
img = imread('000008.png');
[bboxes,scores,labels] = detect(detector,img);

if(~isempty(bboxes))
    img = insertObjectAnnotation(img,'rectangle',bboxes,cellstr(labels));
end
figure
imshow(img)
```
임의의 이미지에 test해봤는데 멍청하다..
![image](https://user-images.githubusercontent.com/69246778/130473090-c00d725d-666d-4d06-bf98-4dc13e266cea.png)
   
![image](https://user-images.githubusercontent.com/69246778/130474158-964b8dba-205f-4607-a945-fbfdac4d05d6.png)
흠 ㅎ.. 아무래도 노트북으로 하다보니 training dataset을 너무 적게 훈련시켜 발생한 문제인 듯하다..
