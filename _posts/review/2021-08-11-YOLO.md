---
layout: post
title: Semminar3 - Perception paper 
description: |
  
tags:
  - review
use_math : true
comments : true
author: Udayeon

published: true
---

# (Review) You Only Look Once : Unified, Real-Time Object Detection

[You Only Look Once : Unified, Real-Time Object Detection](https://ieeexplore.ieee.org/document/7780460)   
- **Author** Joseph Redmon, Santosh Divvala, Ross Girshick, Ali Farhadi
- 2016 IEEE Conference on Computer Vision and Pattern Recognition
{:.message}

**논문 선정 기준**   

  - [Abstract]
  - [1.Introduction]
  - [2. Unified Detection]
  - [3. Comparison to Other Detection Systems]
  - [4. Experiments]
  - [5. Real-Time Detection In The Wild]
  - [6. Conclusion]

# Abstract
* * *

Object detection의 새로운 접근법인 YOLO를 소개. YOLO는 You Only Look Once의 약자임. Object detection에 대한 앞선 연구들은
detection할 때 Classifier를 repurpose(목적에 맞게 수정, 재사용)했음. 근데 우리는 object detection 문제를 regression 문제로 프레임화함.
이 문제는 공간을 분리하는 bounding box와 관련 클래스 확률에 대한 것임. 단일 신경망은 한 번의 평가로, 전체 이미지로부터
bounding box과 클래스 확률을 예측함. 전체 detection pipeline이 단일 network이므로, detection performance에 직접 end-to-end방식으로
최적화된다.

```
NOTE📝
단 한번만 보고도 object를 detection하는 알고리즘이라는 추측을 해봄
Pipe line : 전체 네트워크를 이루는 부분적인 네트워크
end-to-end : 입력에서 출력까지 파이프라인 없이 한 번에 처리하는 것. 파이프라인 없이도 잘 동작할 만틈 많은 데이터가 필요.
             문제가 복잡한 경우, 전체문제(전체 네트워크)를 간단한 문제(파이프라인)으로 나눠서 해결하는 것이 효율적인 경우가
             있음.
```
   
기본 YOLO 모델은 이미지를 초당 45 frame의 속도로 실시간 처리한다. 소규모 네트워크 버전인, Fast YOLO는 초당 155 frame의 속도로 처리하면서
다른 실시간 검출기의 mAP를 두 배로 늘린다. 최신 detection system과 비교했을 때, YOLO는 더 많은 localization error를 만들지만
배경에서 false positive(거짓양성, 1종오류)를 일으킬 확률이 낮다. 마지막으로, YOLO는 Object의 매우 일반적인 표현을 배움. 
자연 이미지에서 DPM이나 R-CNN과 같은 다른 detection method를 능가함.    

```
NOTE📝
mAP : Mean Average Precision, CNN의 성능평가를 위한 지표
False Positive : 1종오류, 
```
   
# 1. Introduction
인간은 이미지를 힐끔만봐도 이미지 안에 어떤 물체가 있고, 어디에 있고, 물체끼리 어떻게 상호작용하는지 즉시 알 수 있음. 인간의 시각은
빠르고 정확해서 의식적인 생각이 별 필요없는 운전과 같은 복잡한 작업을 수행할 수 있음. 빠르고 정확한 object detection은 컴퓨터가
특수한 센서없이 운전하도록 해주고, 보조장치는 인간에게 실시간 scene information을 전달해줄 수 있고 responsive한 로봇 발전의 잠재력도 실현함.
   
현재의 detection system은 classifier를 object에 맞게 선택하고 다양한 location과 scale로 test image를 평가하는 것임. 
DPM(Deformable parts models)같은 시스템은 sliding window approach를 사용하는데 여기서 classifier는 전체 이미지에 걸쳐 균등한 간격으로
실행된다.

```
NOTE📝
Classifier : training sample을 분류하는 알고리즘.
```
[Classifier](https://medium.com/@peteryun/ml-classifiers-%EC%A2%85%EB%A5%98-%EA%B0%84%EB%8B%A8-%EC%A0%95%EB%A6%AC-single-hybrid-ensemble-aabc62eb4b5e)

R-CNN같은 최근의 접근법은 region proposal을 사용해 먼저 이미지에 잠재적 bounding box를 형성한 다음, 이 propose된 box에서 
classifier를 실행한다. classification이 끝나면 bounding box를 refine하고 중복 detection을 제거하며 scene의 다른 object를 기반으로
box에 점수를 매긴다. 이런 복잡한 파이프라인은 각각의 component가 개별적으로 training되어야하므로 최적화하기 느리고 오래걸린다.   
   
우리는 object detection을 single regression문제로 reframe한다. 이 문제는 이미지 픽셀에서 bounding box 및 class probability로 
straight하다. YOLO를 사용하면 물체를 한 번만 보고도 물체가 뭔지, 어딨는지 알 수 있다.

```
NOTE📝
기존의 detection은 Region proposal(Selective Search)로 먼저 잠재적으로 객체가 존재할 가능성이 있는 후보군(Bounding box)들을 추리고 
추려진 후보들에서 classifier를 실행함. 근데, YOLO는 추리는 것 없이 bounding box로 straight하게 진행된다.
```
   
YOLO는 매우 간단함. 
![image](https://user-images.githubusercontent.com/69246778/129288051-2c84ba81-58e9-4643-bc8a-3281e99854f5.png)
먼저 단일 CNN이 전체 이미지에 bounding box를 만들고 class확률을 예측하며 detection성능을 직접 최적화함.
YOLO의 이점은 다음과 같음. 
* 첫 째, 매우 빠름. 탐지를 regression문제로 설정하므로 복잡한 파이프라인이 필요없음. 매우빠른 속도로 실시간 처리가 가능하며 정밀도도 높음
* 둘 째, 예측시 이미지에 대해 global(전역적으로)하게 추론함. sliding window 및 region proposal과 달리 YOLO는 tarining과 test 시간
동안 전체 이미지를 보므로 class의 모양 뿐아니라 상황에 맞는 정보까지 암시적으로 인코딩함. Fast R-CNN과 비교하면 YOLO의 백그라운드 오류는
절반도 안됨. (Fast R-CNN은 큰 context를 보지못함)
* 셋 째, 사물의 일반화된 표현을 학습함. 자연이미지를 훈련하고나서 artwork로 테스트할 때, YOLO는 DPM과 R-CNN같은 상위 detection method를
큰 차이로 능가함. YOLO는 일반화가 용이하므로 예기치 못한 input에 대해서도 적용가능 함.YOLO의 단점은 정확도가 떨어지고, 빠르지만 일부 작은 
객체의 위치는 정확하게 파악하지 못한다는 것임.

```
NOTE📝
YOLO는 single regression 문제이므로 복잡한 파이프라인이 필요없어 매우 빠르다. 그리고 global하게 추론하므로 class자체 뿐 아니라 상황에
맞는 정보까지 제공할 수 있다. 일반화된 표현을 학습하므로 over-fitting 문제 발생이 적다.
단점은, 빠르긴한데 작은 물체에 대한 정확도가 떨어지는 것.
```

# 2. Unified Detection
우리는 object detection의 별도 구성요소를 single neural network로 통합. 우리의 네트워크는 각각의 bounding box를 예측하기 위해
전체 이미지로부터 얻은 feature를 사용하고 이미지의 모든 class에 걸쳐 모든 bounding box를 동시에 예측함. 이는 높은 정밀도를 유지하면서
end-to-end training과 실시간처리를 가능케함.   
   
먼저, input 이미지를 SxS 격자로 나눔. 만약, object의 중심이 grid cell에 속하면, 그 grid cell이 해당 object를 탐지하는 역할을 함. 
각각의 grid cell은 bounding box B와 그 박스들에 해당하는 confidence score를 예측함. 이러한 score는 상자에 객체가 포함되어 있다는
confidence가 어느 정도인지와 그 box가 얼마나 정확히 예측하는지를 반영. 공식적으로 confidence는 Pr(확률) x IOU(실제)로 정의됨. 
만약 cell에 object가 없으면, confidence score는 0이여야 함. 그렇지 않은 경우의 score는 예측과 ground truth의 곱.   
   
각각의 bounding box는 5개 요소(x,y,w,h,confidence)에 대한 예측을 포함. (x,y)는 box의 중심을 나타냄. 전체 이미지를 기준으로 너비와
높이가 예측됨 마지막으로 confidence 예측은 predicted box와 ground truth의 IOU(Intersection Over Union)를 나타냄.   
![image](https://user-images.githubusercontent.com/69246778/129296014-8779b740-2221-47e2-95fa-5d756a9c8a67.png)
