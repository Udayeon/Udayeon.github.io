---
layout: post
title: 
description: |
  Wu, H., Xiao, B., Codella, N., Liu, M., Dai, X., Yuan, L., & Zhang, L. (2021). Cvt: Introducing convolutions to vision transformers. In Proceedings of the IEEE/CVF International Conference on Computer Vision (pp. 22-31).
hide_image: true
tags:
  - review
published: true
---

# CvT: Introducing Convolutions to Vision Transformers
[Link](https://arxiv.org/abs/2103.15808)
* * *
ViT에 Convolution을 도입하며 성능을 개선한다. 아래의 두 가지 방법이 사용된다.
* **Convolution Token Embedding이 포함된 계층 구조**
* **Convolutional projection**
위의 방법을 통해 CNN의 특성(shift,scale,distortion invariance)과 ViT의 특성(동적 어텐션, global context,일반화)
을 모두 유지할 수 있다. 또한, ViT의 **위치인코딩을 제거**해 높은 해상도에서의 비전 작업도 간단한 구조로 수행 가능해졌다.

# 1. Introduction
Vision Trnasformer는 대규모 데이터셋에서는 성능이 매우 좋은데 적은 양의 데이터로 훈력할 때는 CNN이 더 나은 성능을 보인다. 그 이유는,
CNN이 **지역 수용장(local receptive fields), 공유 가중치(shared weights), 공간적 하향 샘플링(spatial subsampling)** 을 사용해
이미지의 지역적 구조를 캡처할 수 있어서 약간의 이동이나 크기 및 왜곡에 대해 불변성을 가질 수 있기 때문이다. 또한 **CNN의 계층적인 
구조**는 다양한 스케일에서 context를 파악할 수 있게 해준다.   
본 논문에서는 위와 같은 **CNN의 특성을 ViT에 접목**시켜 성능을 향상시키다. 이는 성능 뿐만 아니라 매개변수 측면에서도 매우 효율적이다.   
CvT디자인은 다음 두 가지 기법을 제안한다.   
* **Transformer를 여러 단계로 분할해 계층적 구조를 형성한다. 그리고 각 단계의 시작은 합성곱 토큰 임베딩으로 구성되고 
이후 레이어 정규화를 수행한다.**
* **Transformer 모듈에서 각 self-attention블록 이전 단계인 linear projection을 Convolutional projection으로 대체한다.**

# 2. Related Work
## 2.1. Vision Transformers.
데이터 양이 충분한 경우라면 순전파 만으로도 최신 성능을 달성할 수 있는 모델이다. 이미지를 겹치지 않는 패치로 분할하고 이것들 사이에
어텐션을 진행한다. 본 논문은 ViT와 CNN을 결합해 local 및 global 정보를 효율적으로 파악한다.
## 2.2. Introducing Self-attentions to CNNs.

## 2.3. Introducing Convolutions to Transformers.

# 3. Convolutional vision Transformer
## 3.1. Convolutional Token Embedding
## 3.2. Convolutional Projection for Attention
* 3.2.1. Implementation Details
* 3.2.2. Efficiency Considerations
## 3.3. Methodological Discussions
* Relations to Concurrent Work
  
# 4. Experiments
![image](https://github.com/Udayeon/Udayeon.github.io/assets/69246778/7540f3cc-160d-493e-948b-bf967d654e07)
![image](https://github.com/Udayeon/Udayeon.github.io/assets/69246778/7f4aa371-1ba0-4f78-aaa6-5d1aefc7f0d6)
기존 PVT보다 성능 개선되었음.
