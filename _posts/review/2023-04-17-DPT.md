---
layout: post
title: 
description: |
  논문정보(발행일,저자 등)
hide_image: true
tags:
  - review
published: false
---

# DPT: Deformable Patch-based Transformer for Visual Recognition
[Link](https://arxiv.org/abs/2107.14467)
* * *
**DPT 모델**은 고정 크기의 패치 대신 **변형 가능한 패치**를 사용하여 이미지에서 특징을 추출한다. 변형 가능한 패치를 통해
객체의 모양 및 크기에 적응적으로 학습하므로 높은 성능을 달성할 수 있다.

# 1. INTRODUCTION
Vision Trnasformer는 일반적으로 입력 이미지를 **'고정된 크기'** 의 패치로 나누고 multi-head self-attention을 통해 
패치 간의 문맥을 파악한다. CNN보다 장거리 의존성을 효과적으로 포착할 수 있고 추출된 feature에 더 많은 의미를 담는다는 장점이 있다.
그러나 Transformer가 주로 활용하는 **'고정된 크기'** 의 패치 분할은 다음과 같은 문제를 일으킬 수 있다.   
a) 서로 다른 이미지에서 크기가 다른 객체들로 있해 전체적인 객체 관련 지역 구조를 포착하기 어렵다.   
b) 같은 객체라도 이미지에 따라 다른 스케일과 회전을 갖는데 고정된 방식으로 이미지를 나누면 같은 객체인데도 다르게 인식할 수 있다.   
![image](https://user-images.githubusercontent.com/69246778/237038936-99a4b878-281d-4f7a-a1fd-adfc1de32420.png)
위의 사진을 보면, 두 사진 모두 독수리인데 패치 크기가 고정되어 있다보니 a)독수리 발톱을 온전히 포착하지 못하고, b)두 사진의 독수리를 
마치 다른 객체인 것처럼 인식한다.   
본 논문에서는 **DePatch**라는 새로운 모듈을 제안한다. 이 모듈을 PVT에 붙여서 변형 가능한 패치로 이미지를 분할하면 기존의 성능보다
2.3% 높은 분류 정확도를 달성할 수 있다.   
![image](https://user-images.githubusercontent.com/69246778/237039006-1905f92a-5c18-47b2-8d80-672e8e2ae917.png)
DePatch를 이용하면 위의 사진처럼 객체를 더욱 잘 포착하고 그 특징이 더 명확하게 담긴다. 



# 2. RELATED WORK
## 2.1. Vision Transformer
* **Non-Local block and its variants**   
CNN은 공간적으로 가까운 부분만 고려되고 RNN은 시간적으로 가까운 부분만 고려되어 장거리인 경우 문맥을 포착하기 어렵다. 
이를 해소하기 위해 지역에 구애 받지 않는 Non-Local Network가 제안되었다. Gcnet,Ccnet,Non-local neural networks   
* **Only Vision Transformer**   
ViT   
* **DeiT**   
ImageNet에서 훈련된 모델 성능을 향상 시키기 위해 복잡한 학습 스케줄링과 knowledge distillation을 사용한다.   
* **CNN + transformer**   
Explicit Position Encodings for Vision Transformers, Bottleneck transformers   
* **고해상도 피처맵 유지**   
Transformer in transformer, Swin Transformer, Pyramid vision transformer   
* **지역성에 편향 된 매개 변수 추가**   
ConViT, detr with spatially modulated co-attention   
* **무차별적으로 패치 임베딩 모듈 설계**   
Tokens-to-token vit   

## 2.2. Deformable-Related Work
## 1.2. 소제목
어쩔저쩔
