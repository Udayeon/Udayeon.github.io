---
layout: post
title: Deep learning
description: >
  
tags:
  - review
use_math : true
comments : true
author: Udayeon

published: true
---

# Deep learning
[eCun, Y., Bengio, Y. & Hinton, G. Deep learning. Nature 521, 436–444 (2015).](htps://doi.org/10.1038/nature14539)
* * *
딥러닝에 대한 원리,응용,역사 등에 대한 개괄적인 리뷰논문

# Overview
딥러닝은 여러 처리 계층으로 구성된 계산 모델을 이용해 다양한 추상화 단계를 가진 데이터 표현들을 학습한다. 딥러닝은 기계가 그것의 내부 
파라미터를 어떻게 변화 시킬지 구하기 위해 'back propagation'알고리즘을 사용하여 거대한 데이터 집합의 복잡한 구조를 발견한다. 
Deep Convolutional net는 이미지,비디오,음성 및 오디오 처리에 획기적인 발전을, recurrent net 텍스트같은 sequential 데이터에 발전을 가져왔다.

# 1.
기계학습 기술은 현대 사회의 많은 분야(전자상거래 사이트, 카메라, 스마트폰 등등)에 획기적인 발전을 가져왔다. 기계학습 시스템은 이미지에서
물체를 식별하고 음성을 텍스트로 전사하고 뉴스,게시물 등을 사용자의 관심사와 매치시켜 관련 결과를 선택하는 데에 이용된다. 이러한 기능들에
**딥러닝**기술이 점점 더 많이 사용된다.   
   
기존 기계 학습은 데이터를 raw한 형태로 처리하는 능력에 한계가 있었다. 특정한 패턴을 인식 하거나 기계학습 시스템을 구축하기 위해선,
이미지의 픽셀과 같은 raw data를 **특징 추출기**를 통해 적절한 표현 또는 특징벡터로 변환해주어야 했고 이 과정에 상당한 기술과 지식이 필요했다.   
   
**표현 학습**은 기계에 raw data를 제공하고 탐지나 분류에 필요한 표현을 자동으로 검색하는 방법이다. 딥러닝 방식은, 다양한 수준의 표현을
사용하는 표현학습으로, 각각의 표현은 단순하지만 비선형인 모듈을 구성하여 얻어진다. 이처럼 충분한 변환을 통해, 매우 복잡한 기능을 학습할 수
있다. 분류 작업의 경우, 표현 계층이 높을수록 구별에 중요한 input은 증폭되고 관련 없는 변수는 억제된다. 예를 들어, 이미지는 픽셀 값의
배열 형태로 나타나며, **첫 번째** 표현 계층에서 학습된 특징은 일반적으로 이미지의 특정 방향과 위치의 **edge 유무**를 나타낸다. 
**두 번째 층**은 일반적으로 edge의 작은 위치 변동에 관계없이 edge의 특정 배열을 발견해 **motif를 탐지**한다. **세 번째 층**은 
모티프를 익숙한 물체의 일부와 일치하는 더 큰 조합으로 **결합**시키고 **Subsequent**계층은 이러한 부분들의 조합으로써 물체를
탐지한다. 딥러닝의 핵심은 이러한 특징 계층을 인간이 디자인 하는 게 아니라, 범용적인 학습 절차를 사용해 데이터로부터 학습된다는 것이다.   
   
딥러닝은 수년 간, 인공지능 커뮤니티의 노력에도 풀리지 않는 문제들을 해결하는 데 큰 진전을 이루고 있다. 그것은 고차원 데이터의 복잡한
구조를 발견하는 데에 매우 능숙하고, 과학, 기업, 정부의 많은 분야에 적용할 수 있다. (영상인식, 음성인식, 약물 분자 관찰 등등)   
   
우리는 딥러닝이 가까운 미래에 더욱 성공할 것이라 생각한다. 왜냐하면, 그것은 공학자의 수작업은 최소화하기 때문에 사용 가능한 계산과 데이터의
양이 증가하기 때문이다. 현재 심층 신경망을 위해 개발되고 있는 새로운 학습 알고리즘과 아키텍쳐는 이런 진보를 가속화 시킨다.

```
📝NOTE
기존의 기계학습과 달리 딥러닝을 이용한 기계학습은 인간이 수작업으로 해야하는 작업을 최소화하므로 더 많은 데이터와 계산을 다룰 수 있게
한다. 따라서 해결되지 않은 많은 문제들을 해결함에 있어 진전을 보인다.
```


# 2. Supervised Learning
기계 학습의 가장 일반적인 형태는, deep하든 아니든간에 **지도 학습**이다. 우리가 집, 자동차, 사람, 애완동물을 포함한 이미지에 대해 
분류 시스템을 만들고 싶다고 상상해봐라. 우리는 먼저 집,차,사람,동물 각각에 카테고리가 라벨링된 거대한 데이터가 필요하다. 훈련기간 동안,
기계에 이미지가 보여지고 각 카테고리마다 점수의 벡터 형태로 결과를 생성한다. 우리는 원하는 카테고리가 모든 카테고리 중에서 가장 높은 점수를
받길 원하지만, 이는 훈련 전에는 일어날 수 없다. 우리는 실제 결과 점수와 우리가 원했던 점수 사이의 error를 측정하는 목적함수를 계산한다.
그리고, 이 오류를 줄이기 위해 내부 조정 가능한 매개변수를 수정한다. 이 조정가능한 변수들, 흔히 **가중치**라 불리는 이 매개변수들은
기계의 입출력 기능을 정의하는 'knobs'가 되는 실수이다. 일반적인 딥러닝 시스템에서, 이러한 조정 가능한 가중치와 기계를 훈련시킬 라벨링된 예시가 수억 개에 달할 수 있다.   
   
가중치 벡터를 적절히 조정하기 위해, 학습 알고리즘은 각각의 가중치가 소량 증가했을 경우 오류가 증가하거나 감소하는 **기울기 벡터**를 구한다.
가중치 벡터는 이 기울기 벡터의 반대 방향으로 조정된다.   
   
모든 훈련 예제를 거쳐 평균화 된 목적함수는 가중치 값의 고차원 공간에서 언덕이 많은 풍경으로 볼 수 있다. 음의 기울기 벡터는 이 공간에서, 
output error가 평균적으로 낮은 최소값에 근접할 수 있도록 이 지형에서 가장 급하강하는 방향을 보여준다.   
   
실제로, 대부분의 실무자들은 **스토캐스틱 경사 하강법(Stochastic Gradient Descent)** 을 사용한다. 이것은 몇가지 예제에 대한 input 벡터를
보여주고, 출력과 에러, 평균 기울기를 계산하고 그에 따라 가중치를 조정하는 것으로 구성된다. 그 과정은 목적함수의 평균이 감소하다가 멈출 때
까지 훈련 세트의 많은 small set들을 반복한다. 이것이 스토캐스틱(확률적)이라 불리는 것은, 모든 예제에 걸쳐 평균 기울기의 
**noisy estimate**를 제공하기 때문이다. 이 간단한 절차는, 정교한 최적화 기법과 비교했을 때 놀랍도록 빠르게 좋은 가중치 세트를 발견한다.
트레이닝 이후에, 시스템의 성능은 test set라 하는 다른 예제 세트에서 측정된다. 이는 기계의 **일반화 능력**을  테스트한다.   
   
현재 기계학습의 많은 실제 적용은 수공학적 특징 위에 선형 분류기를 사용한다. 2-class 선형분류기는 특징 벡터 성분의 가중합계(weighted sum)를
계산한다. 가중합계가 threshold를 초과하는 경우, input은 특정 카테고리에 속하는 것으로 간주된다.   
   
1960년대 이후로, 우리는 선형 분류기가 input을 매우 단순한 영역, 즉 초평면으로 구분된 빈 공간으로만 나눌 수 있음을 알았다. 
그러나, 이미지와 음성 인식과 같은 문제는 입출력 기능이 특정한 미세 변화에 매우 민감하면서 관련 없는 변화에는 둔감해야 한다. 
예를 들어, 흰 늑대와 늑대 같이 생긴 흰색 품종견의 차이를 비교해보자. 픽셀 수준에서, 서로 다른 위치와 다른 환경에 있는 두 dog은 서로 매우 
다를 수 있는 반면에, 같은 위치와 비슷한 배경이면 강아지와 늑대가 매우 유사할 수 있다. raw pixel에 적용되는 선형 분류기, 또는 'shallow'
분류기는, 전자의 둘(다른 환경에 있는 두 강아지)은 같은 범주로 분류할 수 있지만 후자의 둘(개와 늑대)을 구별할 수 없다. 
따라서, shallow 분류기는 **Selectivity-invariance dilemma**를 해결하는 좋은 특징 추출기를 필요로 한다. 즉, 구별하는데 중요한 이미지
측면에서는 선택적이지만, 동물의 포즈 같은 관련없는 측면에 대해선 불변하는 표현을 생성하는 것이다. 분류기를 더 강력하게 만들기 위해, 
커널 방법을 통해, 일반적인 비선형 특징을 사용할 수 있지만 **가우시안 커널**과 같은 일반적인 특징은 학습자를 일반화하기 어렵게 만든다. 
기존의 옵션은 뛰어난 특징 추출기를 수작업으로 설계하므로 공학자의 스킬과 전문 지식이 필요하다. 그러나, 범용학습절차를 사용해 이를 피하는 것이
딥러닝의 장점이다.   
   
딥러닝은 단순 모듈의 다층적 stack인데 이 stack의 각 모듈들이 입력값을 변환하여 **Selectivity**와 **invariance**를 증가시킨다. 즉, 깊이가
5~20인 여러 개의 비선형 레이어를 사용하면 시스템은 디테일엔 민감하고 필요없는 정보엔 둔감해져 매우 복잡한 기능을 구현할 수 있다.

```
📝NOTE
기계학습에서 대표적으로 사용되는 방식은 지도학습이다. 지도학습은 정답값이 라벨링 되어있는 수많은 데이터를 이용해 학습한 기계가 test data를
분류하도록 하는 것이다. 이 때, 정답값(학습할 때 사용된 라벨링된 데이터)과 예측값의 오류를 최소화해야 하므로 이 둘을 이용한 목적함수를 설계하고
이 함수가 최소가 되도록 가중치 매개변수들을 수정한다. 대부분의 실무에서는 '스토캐스틱 경사 하강법'을 이용해 좋은 가중치를 빠르게 선택한다.
   
기계학습은 주로 선형분류기를 사용하는데, 선형분류기로는 복잡한 작업에 한계가 있으므로 다층적 stack을 사용한 분류기를 활용한 딥러닝을 사용하면
복잡한 작업(중요 정보에는 민감하게 반응하고 필요없는 정보에는 둔감하게 반응하는)을 수행할 수 있다.
```

# 3. Backpropagation to train multilayer architectures
수공학적 특징(공학자들이 손으로 직접 특징을 입력해야함)을 훈련가능한 다층 네트워크로 대체하는 방법. 
목적 함수의 기울기를 계산하는 역전파 절차는 미분의 chain rule을 실제 적용한 것이다. 
핵심 아이디어는 모듈의 input에 대한 objective(목적함수)의 미분(또는 기울기)을 역방향으로 계산한다는 것이다. 
역전파 방정식은 네트워크가 예측을 생성하는 곳(출력층)부터 외부 입력을 받아들이는 곳(입력층)까지 모든 모듈을 통해 기울기를 전파하기 위해 
반복적으로 적용될 수 있다. 일단 기울기가 계산되면, 각각 모듈에서의 가중치와 관련된 기울기를 계산하는 것은 간단하다.   
   
딥러닝의 많은 application들은 고정된 크기의 input을 고정된 크기의 output에 매핑하는 방법을 학습하는 **feedforward neural network** 
아키텍처를 사용한다. 한 계층에서 다음으로 넘어가기 위해, 단위 집합은 이전 layer에서 입력의 가중합을 계산하고 비선형 함수를 통해 이를 전달한다.
현재, 가장 대표적으로 사용되는 비선형 함수는 **ReLU**함수이며 이는 단순히 **half-wave rectifier**이다. 지난 수십년간, 신경망은 tanh(z)나 
1/(1+exp(-z)) 함수를 사용했다, 그러나 ReLU는 일반적으로 비지도 사전 훈련 없이도 많은 계층이 있는 네트워크에서 훨씬 빨리 지도(supervised)
네트워크를 학습한다. 입출력 계층에 없는 unit을 일반적으로 **hidden units**이라 한다. **hidden layers**는 비선형 방식으로 input을 
왜곡함으로써 마지막 레이어에 의해 선형으로 분리될 수 있게 한다.   
   
1990년대 후반, 신경망과 역전파는 대부분 버림받고 컴퓨터 비전과 음성인식 분야에서는 무시되었다. 사전지식이 거의 없는 multilayer 특징 
추출기를 유용하게 학습하기란 실현 불가능하다고 생각되었다. 특히, 간단한 Gradient descent는 열악한(poor) local minima, 즉, 작은 변화 없이 
평균 오차를 줄이는 가중치 구성에 의해 제한될 것이라 생각됐다. 
   
열악한(poor) local minima는 대형 시스템에선 거의 문제가 되지 않는다. 초기 조건에 상관없이, 시스템은 거의 항상 비슷한 퀄리티의 
솔루션에 도달한다. 
최근 이론적,경험적인 결과는 local minima가 일반적으로 심각한 문제가 아님을 강력하게 제시한다. 대신, landscape는 gradient가 0인 
많은 **인장점**들로 조합되어 있고, 표면은 대부분의 차원 위로 휘어지고 나머지에서는 아래로 휘어진다. 분석 결과, 아래 방향으로 휘어지는 
소수의 인장점이 매우 큰 수로 존재하는 것처럼 보이지만, 그들 중 대부분은 목적함수와 매우 유사한 값을 가지고 있다. 따라서, 알고리즘이 어떤 인장
지점에 있는지는 중요치않다.   
![image](https://user-images.githubusercontent.com/69246778/141731505-a6a2aea2-bf4d-4735-a74d-bfd7bd5cb82d.png)
   
**deep feedforward network**에 대한 관심은 2006년 경, CIFAR가 함께 참여한 연구 그룹에 의해 되살아났다. 연구자들은 라벨링된 데이터 없이
특징 검출기 layer를 만들 수 있는 **비지도학습**을 도입했다. 특징 검출기의 각 layer를 학습하는 목적은 그 layer 하에서 특징 검출기 또는 
raw input의 활동을 재구성하거나 모델링하는 것이다. 이 재구성된 objective를 사용하여 좀 더 복잡한 특징 검출기의 여러 층을 **사전학습**
함으로써 심층신경망의 가중치를 합리적인 값으로 초기화할 수 있다. 그런 다음, 네트워크 맨 위에 최종 출력 장치를 추가하고, 표준 역전파를 활용해
전체 시스템을 미세조정할 수 있다. 이는 특히 라벨링 된 데이터의 양이 매우 제한적인 경우, 손글씨나 감지나 보행자 인식과 같은 일들을 효과적으로
해냈다.   
   
그러나, 인접 계층 간에 **full connectivity**를 갖는 네트워크보다 훨씬 훈련하기 쉽고 일반화가 잘 된 deep feedforward network가 있는데
그것이 바로 **Convolution Neural Network**이다. 이는 컴퓨터 비전에 널리 사용되었다.
   
```
📝NOTE
목적함수의 기울기 계산을 위해 'backpropagation'을 사용하는데, 이는 출력층부터 입력층까지 목적함수의 기울기를 역으로 계산하는 것으로 
'chain rule'을 활용한다. 딥러닝에서 대표적으로 사용되는 활성화함수는 ReLU함수이며, 'hidden layers'는 input을 비선형 방식으로 왜곡하여
최종적으로 선형 분리되게 해준다. 
deep feedforward network
Convolution Neural network : full connectivity가 아닌 부분연결 사용
```

# 4. Convolutional neural networks
**convolution network**는 세 개의 2D 배열로 구성된(RGB) 컬러 이미지 등 여러 배열 형태로 제공되는 데이터를 처리하도록 설계되었다. 
많은 데이터들의 양식이 다중 배열의 형태로 구성되어 있다: 언어를 포함한 신호는 1D, 이미지나 오디오 spectrogram은 2D, 비디오나 볼륨 이미지는
3D 등...  ConvNets에는 **local connetions, shared weights, pooling, The use of many layers** 4가지 핵심 아이디어로 자연 신호의
특성을 활용한다.   


