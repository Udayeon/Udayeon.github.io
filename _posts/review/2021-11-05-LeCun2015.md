---
layout: post
title: Deep learning
description: >
  
tags:
  - review
use_math : true
comments : true
author: Udayeon

published: true
---

# Deep learning
[eCun, Y., Bengio, Y. & Hinton, G. Deep learning. Nature 521, 436–444 (2015).](htps://doi.org/10.1038/nature14539)
* * *
딥러닝에 대한 원리,응용,역사 등에 대한 개괄적인 리뷰논문

# Overview
딥러닝은 여러 처리 계층으로 구성된 계산 모델을 이용해 다양한 추상화 단계를 가진 데이터 표현들을 학습한다. 딥러닝은 기계가 그것의 내부 
파라미터를 어떻게 변화 시킬지 구하기 위해 'back propagation'알고리즘을 사용하여 거대한 데이터 집합의 복잡한 구조를 발견한다. 
Deep Convolutional net는 이미지,비디오,음성 및 오디오 처리에 획기적인 발전을, recurrent net 텍스트같은 sequential 데이터에 발전을 가져왔다.

# 1.
기계학습 기술은 현대 사회의 많은 분야(전자상거래 사이트, 카메라, 스마트폰 등등)에 획기적인 발전을 가져왔다. 기계학습 시스템은 이미지에서
물체를 식별하고 음성을 텍스트로 전사하고 뉴스,게시물 등을 사용자의 관심사와 매치시켜 관련 결과를 선택하는 데에 이용된다. 이러한 기능들에
**딥러닝**기술이 점점 더 많이 사용된다.   
   
기존 기계 학습은 데이터를 raw한 형태로 처리하는 능력에 한계가 있었다. 특정한 패턴을 인식 하거나 기계학습 시스템을 구축하기 위해선,
이미지의 픽셀과 같은 raw data를 **특징 추출기**를 통해 적절한 표현 또는 특징벡터로 변환해주어야 했고 이 과정에 상당한 기술과 지식이 필요했다.   
   
**표현 학습**은 기계에 raw data를 제공하고 탐지나 분류에 필요한 표현을 자동으로 검색하는 방법이다. 딥러닝 방식은, 다양한 수준의 표현을
사용하는 표현학습으로, 각각의 표현은 단순하지만 비선형인 모듈을 구성하여 얻어진다. 이처럼 충분한 변환을 통해, 매우 복잡한 기능을 학습할 수
있다. 분류 작업의 경우, 표현 계층이 높을수록 구별에 중요한 input은 증폭되고 관련 없는 변수는 억제된다. 예를 들어, 이미지는 픽셀 값의
배열 형태로 나타나며, **첫 번째** 표현 계층에서 학습된 특징은 일반적으로 이미지의 특정 방향과 위치의 **edge 유무**를 나타낸다. 
**두 번째 층**은 일반적으로 edge의 작은 위치 변동에 관계없이 edge의 특정 배열을 발견해 **motif를 탐지**한다. **세 번째 층**은 
모티프를 익숙한 물체의 일부와 일치하는 더 큰 조합으로 **결합**시키고 **Subsequent**계층은 이러한 부분들의 조합으로써 물체를
탐지한다. 딥러닝의 핵심 측변은 이러한 특징 계층을 인간이 디자인 하는 게 아니라, 범용적인 학습 절차를 사용해 데이터로부터 학습된다는 것이다.   
   
딥러닝은 수년 간, 인공지능 커뮤니티의 노력에도 풀리지 않는 문제들을 해결하는 데 큰 진전을 이루고 있다. 그것은 고차원 데이터의 복잡한
구조를 발견하는 데에 매우 능숙하고, 과학, 기업, 정부의 많은 분야에 적용할 수 있다. (영상인식, 음성인식, 약물 분자 관찰 등등)   
   
우리는 딥러닝이 가까운 미래에 더욱 성공할 것이라 생각한다. 왜냐하면, 그것은 공학자의 수작업은 최소화하기 때문에 사용 가능한 계산과 데이터의
양이 증가하기 때문이다. 현재 심층 신경망을 위해 개발되고 있는 새로운 학습 알고리즘과 아키텍쳐는 이런 진보를 가속화 시킨다.

```
📝NOTE
기존의 기계학습과 달리 딥러닝을 이용한 기계학습은 인간이 수작업으로 해야하는 작업을 최소화하므로 더 많은 데이터와 계산을 다룰 수 있게
한다. 따라서 해결되지 않은 많은 문제들을 해결함에 있어 진전을 보인다.
```


# 2. Supervised Learning
기계 학습의 가장 일반적인 형태는, deep하든 아니든간에 **지도 학습**이다. 우리가 집, 자동차, 사람, 애완동물을 포함한 이미지에 대해 
분류 시스템을 만들고 싶다고 상상해봐라. 우리는 먼저 집,차,사람,동물 각각에 카테고리가 라벨링된 거대한 데이터가 필요하다. 훈련기간 동안,
기계에 이미지가 보여지고 각 카테고리마다 점수의 벡터 형태로 결과를 생성한다. 우리는 원하는 카테고리가 모든 카테고리 중에서 가장 높은 점수를
받길 원하지만, 이는 훈련 전에는 일어날 수 없다. 우리는 실제 결과 점수와 우리가 원했던 점수 사이의 error를 측정하는 목적함수를 계산한다.
그리고, 이 오류를 줄이기 위해 내부 조정 가능한 매개변수를 수정한다. 이 조정가능한 변수들, 흔히 **가중치**라 불리는 이 매개변수들은
기계의 입출력 기능을 정의하는 'knobs'가 되는 실수이다. 일반적인 딥러닝 시스템에서, 이러한 조정 가능한 가중치와 기계를 훈련시킬 라벨링된 예시가 수억 개에 달할 수 있다.   
   
가중치 벡터를 적절히 조정하기 위해, 학습 알고리즘은 각각의 가중치가 소량 증가했을 경우 오류가 증가하거나 감소하는 **기울기 벡터**를 구한다.
가중치 벡터는 이 기울기 벡터의 반대 방향으로 조정된다.   
   
모든 훈련 예제를 거쳐 평균화 된 목적함수는 가중치 값의 고차원 공간에서 언덕이 많은 풍경으로 볼 수 있다. 음의 기울기 벡터는 이 공간에서, 
output error가 평균적으로 낮은 최소값에 근접할 수 있도록 이 지형에서 가장 급하강하는 방향을 보여준다.   
   
실제로, 대부분의 실무자들은 **스토캐스틱 경사 하강법(Stochastic Gradient Descent)** 을 사용한다. 이것은 몇가지 예제에 대한 input 벡터를
보여주고, 출력과 에러, 평균 기울기를 계산하고 그에 따라 가중치를 조정하는 것으로 구성된다. 그 과정은 목적함수의 평균이 감소하다가 멈출 때
까지 훈련 세트의 많은 small set들을 반복한다. 이것이 스토캐스틱(확률적)이라 불리는 것은, 모든 예제에 걸쳐 평균 기울기의 
**noisy estimate**를 제공하기 때문이다. 이 간단한 절차는, 정교한 최적화 기법과 비교했을 때 놀랍도록 빠르게 좋은 가중치 세트를 발견한다.
트레이닝 이후에, 시스템의 성능은 test set라 하는 다른 예제 세트에서 측정된다. 이는 기계의 **일반화 능력**을  테스트한다.   
   
현재 기계학습의 많은 실제 적용은 수공학적 특징 위에 선형 분류기를 사용한다. 2-class 선형분류기는 특징 벡터 성분의 가중합계(weighted sum)를
계산한다. 가중합계가 threshold를 초과하는 경우, input은 특정 카테고리에 속하는 것으로 간주된다.   
   
1960년대 이후로, 우리는 선형 분류기가 input을 매우 단순한 영역, 즉 초평면으로 구분된 빈 공간으로만 나눌 수 있음을 알았다. 
그러나, 이미지와 음성 인식과 같은 문제는 입출력 기능이 특정한 미세 변화에 매우 민감하면서 관련 없는 변화에는 둔감해야 한다. 
예를 들어, 흰 늑대와 늑대 같이 생긴 흰색 품종견의 차이를 비교해보자. 픽셀 수준에서, 서로 다른 위치와 다른 환경에 있는 두 dog은 서로 매우 
다를 수 있는 반면에, 같은 위치와 비슷한 배경이면 강아지와 늑대가 매우 유사할 수 있다. raw pixel에 적용되는 선형 분류기, 또는 'shallow'
분류기는, 전자의 둘(다른 환경에 있는 두 강아지)은 같은 범주로 분류할 수 있지만 후자의 둘(개와 늑대)을 구별할 수 없다. 
따라서, shallow 분류기는 **Selectivity-invariance dilemma**를 해결하는 좋은 특징 추출기를 필요로 한다. 즉, 구별하는데 중요한 이미지
측면에서는 선택적이지만, 동물의 포즈 같은 관련없는 측면에 대해선 불변하는 표현을 생성하는 것이다. 분류기를 더 강력하게 만들기 위해, 
커널 방법을 통해, 일반적인 비선형 특징을 사용할 수 있지만 **가우시안 커널**과 같은 일반적인 특징은 학습자를 일반화하기 어렵게 만든다. 
기존의 옵션은 뛰어난 특징 추출기를 수작업으로 설계하므로 공학자의 스킬과 전문 지식이 필요하다. 그러나, 범용학습절차를 사용해 이를 피하는 것이
딥러닝의 장점이다.   
   
딥러닝은 단순 모듈의 다층적 stack인데 이 stack의 각 모듈들이 입력값을 변환하여 **Selectivity**와 **invariance**를 증가시킨다. 즉, 깊이가
5~20인 여러 개의 비선형 레이어를 사용하면 시스템은 디테일엔 민감하고 필요없는 정보엔 둔감해져 매우 복잡한 기능을 구현할 수 있다.



