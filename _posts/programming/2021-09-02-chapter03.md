---
layout: post
title: (Python) 파이썬과 Opencv를 이용한 컴퓨터 비전 학습 Chapter03
description: |
  Opencv3 computer vision with python cookbook
hide_image: true
tags:
  - programming
published: true
---

# (Python) 파이썬과 Opencv를 이용한 컴퓨터 비전 학습 Chapter03

(Python) 파이썬과 Opencv를 이용한 컴퓨터 비전 학습 Chapter03

# Chapter03.윤곽선과 분할
* * *
픽셀은 단지 저장된 값 자체만을 알려줄 뿐 그 이상은 아니다. 윤곽선을 이용해 객체를 찾고, 인스턴스를 다른 인스턴스와 분리해 최종적으로 전체 장면을 이해하므로 윤곽선과 분할은 컴퓨터 비전에서 매우 중요하다

## 1. Otsu알고리즘을 사용한 그레이스케일 이미지의 이진화
```py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import cv2
import numpy as np
import matplotlib.pyplot as plt

image = cv2.imread('../data/Lena.png',0)

#Otus방법으로 임계값을 추정한다.
otsu_thr,otsu_mask = cv2.threshold(image,-1,1,cv2.THRESH_BINARY|cv2.THRESH_OTSU)
print('Estimated threshold (Otsu):',otsu_thr)

plt.figure()
plt.subplot(121)
plt.axis('off')
plt.title('original')
plt.imshow(image,cmap='gray')

plt.subplot(122)
plt.axis('off')
plt.title('Otsu threshold')
plt.imshow(otsu_mask,cmap='gray')

plt.tight_layout(True)
plt.show()
```

![스크린샷, 2021-09-14 15-06-53](https://user-images.githubusercontent.com/69246778/133203883-825741f1-ccc5-4a3f-bf69-50b9a41583ea.png)


## 2. 이진 이미지에서 외부 및 내부 윤곽선 찾기
```py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import cv2
import numpy as np
import matplotlib.pyplot as plt

#이진 이미지를 불러온다
image = cv2.imread('../data/BnW.png',0)

#외부 및 내부 윤곽선을 찾아 2단계의 계층으로 조직화
_,contours,hierarchy = cv2.findContours(image,cv2.RETR_CCOMP, cv2.CHAIN_APPROX_SIMPLE)

#외부 윤곽선 이진 마스크를 준비한다.
image_external = np.zeros(image.shape,image.dtype)
for i in range(len(contours)):
    if hierarchy[0][i][3]==-1:
        cv2.drawContours(image_external,contours,i,255,-1)
        


#내부 윤곽선 이진 마스크를 준비한다.
image_internal = np.zeros(image.shape,image.dtype)
for i in range(len(contours)):
    if hierarchy[0][i][3]!=-1:
        cv2.drawContours(image_internal,contours,i,255,-1)
        
#결과
plt.figure(figsize=(10,3))

plt.subplot(131)
plt.axis('off')
plt.title('original')
plt.imshow(image,cmap='gray')

plt.subplot(132)
plt.axis('off')
plt.title('external')
plt.imshow(image_external,cmap='gray')

plt.subplot(133)
plt.axis('off')
plt.title('internal')
plt.imshow(image_internal,cmap='gray')

plt.tight_layout(True)

plt.show()
```
![스크린샷, 2021-09-14 15-14-59](https://user-images.githubusercontent.com/69246778/133204781-a6d30da5-3cf9-4eff-bd17-5862c3b8be88.png)

## 3. 이진 이미지에서 연결된 구성 요소 추출
```py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import cv2
import numpy as np

#이미지를 열어 연결된 요소 찾기
img = cv2.imread('../data/BnW.png',cv2.IMREAD_GRAYSCALE)

connectivity = 8
num_labels,labelmap = cv2.connectedComponents(img,connectivity, cv2.CV_32S)

#CV_32S : 32-bit signed integer: int ( -2147483648..2147483647 )


#원본이미지와 레이블로 스케일링 된 이미지를 함께 표시
img = np.hstack((img,labelmap.astype(np.float32)/(num_labels)))
cv2.imshow('Connected components',img)
cv2.waitKey()
cv2.destroyAllWindows()

#다른 이미지를 열어 otsu마스크를 찾고 연결된 요소와 통계 자료를 얻음
img  = cv2.imread('../data/Lena.png',cv2.IMREAD_GRAYSCALE)
otsu_thr,otsu_mask = cv2.threshold(img,-1,1,cv2.THRESH_BINARY | cv2.THRESH_OTSU)
output = cv2.connectedComponentsWithStats(otsu_mask,connectivity, cv2.CV_32S)


num_labels, labelmap, stats, centers = output

colored = np.full(((img.shape[0]),img.shape[1],3),0,np.uint8)

for l in range(1, num_labels):
    if stats[l][4] > 200:
        colored[labelmap == l] = (0, 255*l/num_labels, 255*num_labels/l)
        cv2.circle(colored, (int(centers[l][0]),int(centers[l][1])),5,(255,0,0),cv2.FILLED)
        img = cv2.cvtColor(otsu_mask*255, cv2.COLOR_GRAY2BGR)

cv2.imshow('Connected components', np.hstack((img,colored)))
cv2.waitKey()
cv2.destroyAllWindows()
```
![스크린샷, 2021-09-15 13-17-26](https://user-images.githubusercontent.com/69246778/133369849-2388604b-2bd1-450b-a0b1-7df48dd7df06.png)
![스크린샷, 2021-09-15 13-17-32](https://user-images.githubusercontent.com/69246778/133369847-851a3a92-7eb6-4167-9dc3-773cd7f06189.png)

## 4. 선과 원을 2차원 점의 집합으로 맞추기
```py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import cv2
import numpy as np
import random

img = np.full((512,512,3), 255, np.uint8)

#타원을 그리기 위한 반축과 회적각을 임의로 설정
axes=(int(256*random.uniform(0,1)),int(256*random.uniform(0,1)))
angle = int(180*random.uniform(0,1))
center = (256,256)

#생성된 매개변수로 타원에 해당하는 점을 생성하고 임의의 노이즈 추가
pts = cv2.ellipse2Poly(center,axes,angle,0,360,1)
pts += np.random.uniform(-10,10,pts.shape).astype(np.int32)

#이미지 위에 타원을 그리고 점 표시
cv2.ellipse(img,center,axes,angle,0,360,(0,255,0),3)

for pt in pts:
    cv2.circle(img,(int(pt[0]),int(pt[1])),3,(0,0,255))

cv2.imshow('Fir ellipse',img)
cv2.waitKey()
cv2.destroyAllWindows()

                                            
#노이즈인 점에 가장 잘 맞는 타원의 매개변수를 찾아 해당 타원을 표시
ellipse = cv2.fitEllipse(pts)
cv2.ellipse(img,ellipse,(0,0,0),3)

cv2.imshow('Fit ellipse',img)
cv2.waitKey()
cv2.destroyAllWindows()

#빈 이미지를 생성하고 y=x함수에 해당하는 점을 생성에 노이즈 추가
img = np.full((512,512,3),255,np.uint8)
pts = np.arange(512).reshape(-1,1)
pts = np.hstack((pts,pts))
pts += np.random.uniform(-10,10,pts.shape).astype(np.int32)

cv2.line(img,(0,0),(512,512),(0,255,0),3)

for pt in pts:
    cv2.circle(img,(int(pt[0]),int(pt[1])),3,(0,0,255))

cv2.imshow('Fit line',img)
cv2.waitKey()
cv2.destroyAllWindows()


vx,vy,x,y = cv2.fitLine(pts,cv2.DIST_L2,0,0.01,0.01)
y0 = int(y - x*vy/vx)
y1 = int((512-x)*vy/vx+y)
cv2.line(img,(0,y0),(512,y1),(0,0,0),3)

cv2.imshow('Fit line',img)
cv2.waitKey()
cv2.destroyAllWindows()
```

## 5. 이미지 모멘트 계산 
```py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import cv2
import numpy as np
import matplotlib.pyplot as plt

image = np.zeros((480,640),np.uint8)
cv2.ellipse(image,(320,240),(200,100),0,0,360,355,-1)

m=cv2.moments(image)
for name, val in m.items():
    print(name,'\t',val)
    

print('Center X estimated:',m['m10']/m['m00'])
print('Center Y estimated:',m['m01']/m['m00'])
```
```
>>>
m00 	 16119315.0
m10 	 5158101240.0
m01 	 3868620810.0
m20 	 1812142855350.0
m11 	 1237939564800.0
m02 	 969157708320.0
m30 	 683285449618080.0
m21 	 434912202354750.0
m12 	 310125260718570.0
m03 	 252129278267070.0
mu20 	 161575917357.31616
mu11 	 -72.9990234375
mu02 	 40692263506.42969
mu30 	 1687957749.125
mu21 	 -420182048.71875
mu12 	 -422443285.20703125
mu03 	 105694127.71875
nu20 	 0.0006218468887998859
nu11 	 -2.809466679966455e-13
nu02 	 0.00015660970937729079
nu30 	 1.618061841335058e-09
nu21 	 -4.0278291313762605e-10
nu12 	 -4.049505150683136e-10
nu03 	 1.013174855849065e-10
Center X estimated: 319.9950643063927
Center Y estimated: 239.999082467214
```

## 6. 곡선으로 작업: 근사, 길이, 면적
```py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import cv2
import random
import numpy as np

img = cv2.imread('../data/bw.png',cv2.IMREAD_GRAYSCALE)

#불러온 이미지의 윤곽선 표시
im2, contours, hierarchy = cv2.findContours(img,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)

color = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
cv2.drawContours(color, contours, -1, (0,255,0),3)
cv2.imshow('contours',img)
cv2.waitKey()
cv2.destroyAllWindows()

#첫 번째 윤곽선을 받아 다양한 경우에 대한 면적을 계산해 결과를 출력
contour = contours[0]

print('Area of contour is %.2f' % cv2.contourArea(contour))
print('Signed area of contour is %.2f' % cv2.contourArea(contour,True))
print('Signed area of contour is %.2f' % cv2.contourArea(contour[::-1],True))

#윤곽선의 길이 계산
print('Length of closed contour is %.2f' %cv2.arcLength(contour,True))
print('Length of open contour is %.2f' % cv2.arcLength(contour,False))

#윤곽선의 볼록 외피를 화면에 출력
hull = cv2.convexHull(contour)
cv2.drawContours(color,[hull],-1,(0,0,255),3)

cv2.imshow('contours',color)
cv2.waitKey()
cv2.destroyAllWindows()


#윤곽선 외피의 볼록 여부 확인
print('Convex status of contour is %s' % cv2.isContourConvex(contour))
print('Convex status of its hull is %s' % cv2.isContourConvex(hull))


#윤곽선 근사에 대한 품질 제어 트랙바를 생성하고 이를 이용해 근사된 외곽선을 출력
cv2.namedWindow('contours')

img=np.copy(color)

def trackbar_callback(value):
    global img
    epsilon = value*cv2.arcLength(contour,True)*0.1/255
    approx = cv2.approxPolyDP(contour,epsilon,True)
    img=np.copy(color)
    cv2.drawContours(img,[approx],-1,(255,0,255),3)

cv2.createTrackbar('Epsilon','contours',1,255,lambda v: trackbar_callback(v))
while True:
    cv2.imshow('contours',img)
    key=cv2.waitKey(3)
    if key ==27:
        break

cv2.destroyAllWindows()
```
```
>>>
Area of contour is 47474.00
Signed area of contour is -47474.00
Signed area of contour is 47474.00
Length of closed contour is 1905.29
Length of open contour is 1897.29
Convex status of contour is False
Convex status of its hull is True
```
![스크린샷, 2021-09-15 14-06-55](https://user-images.githubusercontent.com/69246778/133373991-6ac853ca-b262-4519-aac0-664e0d196787.png)

## 7. 윤곽선 내부에서 점의 포함 여부 확인
```py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import cv2
import random
import numpy as np

img= cv2.imread('../data/bw.png',cv2.IMREAD_GRAYSCALE)

#윤곽선 찾기
im2,contours,hierarchy = cv2.findContours(img,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)

color = cv2.cvtColor(img,cv2.COLOR_GRAY2BGR)
cv2.drawContours (color,contours,-1,(0,255,0),3)

cv2.imshow('contours',color)
cv2.waitKey()
cv2.destroyAllWindows()


#이미지 클릭을 처리하는 콜백 함수 정의, 클린된 위치에 작은 원을그리고 그려지는 원의 색상이 윤곽선 포함 여부에 따라 결정
contour = contours[0]
image_to_show=np.copy(color)
measure = True

def mouse_callback(event,x,y,flags,param):
    global contour, image_to_show
    if event == cv2.EVENT_LBUTTONUP:
        distance = cv2.pointPolygonTest(contour,(x,y),measure)
        image_to_show = np.copy(color)

        if distance > 0:
            pt_color = (0,255,0)
        elif distance <0:
            pt_color = (0,0,255)
        else:
            pt_color = (128,0,128)

        cv2.circle(image_to_show,(x,y),5,pt_color,-1)
        cv2.putText(image_to_show, '%.2f' % distance,(0,image_to_show.shape[1] -5), cv2.FONT_HERSHEY_SIMPLEX,1,(255,255,255))


#마우스 클릭 핸들러로 이미지를 표시, 키보드 M키를 누르면 모드 전환
cv2.namedWindow('contours')
cv2.setMouseCallback('contours',mouse_callback)

while(True):
    cv2.imshow('contours',image_to_show)
    k=cv2.waitKey()

    if k == ord('m'):
        measure = not measure
    elif k==27:
        break

cv2.destroyAllWindows()
```
![스크린샷, 2021-09-15 14-19-18](https://user-images.githubusercontent.com/69246778/133375076-ebe55621-49ba-4bf6-a033-7696535a5ece.png)
![스크린샷, 2021-09-15 14-19-13](https://user-images.githubusercontent.com/69246778/133375077-95e018bf-3a4b-4b60-a065-356848934b21.png)

## 8. 거리맵 계산
```py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import cv2
import numpy as np
import matplotlib.pyplot as plt

image= np.full((480,640),255,np.uint8)
cv2.circle(image,(320,240),100,0)

distmap = cv2.distanceTransform(image,cv2.DIST_L2,cv2.DIST_MASK_PRECISE)

plt.figure()
plt.imshow(distmap,cmap='gray')
plt.show()
```
![스크린샷, 2021-09-15 14-49-28](https://user-images.githubusercontent.com/69246778/133377837-ba72d005-ce08-4fc7-ab93-a0b8c11ac471.png)

## 9. k-평균 알고리즘을 이용한 이미지 분할
```py
#!/usr/bin/env python3
# -*- coding: utf-8 -*-

import cv2
import numpy as np
import matplotlib.pyplot as plt

image = cv2.imread('../data/Lena.png').astype(np.float32)/255
image_lab = cv2.cvtColor(image,cv2.COLOR_BGR2Lab)

data = image_lab.reshape((-1,3))


num_classes = 4
criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER,50,0.1)

_,labels,centers = cv2.kmeans(data,num_classes, None, criteria, 10, cv2.KMEANS_RANDOM_CENTERS)

segmented_lab = centers[labels.flatten()].reshape(image.shape)
segmented = cv2.cvtColor(segmented_lab, cv2.COLOR_Lab2RGB)

plt.subplot(121)
plt.axis('off')
plt.title('original')
plt.imshow(image[:,:,[2,1,0]])

plt.subplot(122)
plt.axis('off')
plt.title('segmented')
plt.imshow(segmented)

plt.show()
```
![스크린샷, 2021-09-15 14-58-46](https://user-images.githubusercontent.com/69246778/133378813-fb4e5733-2e92-4ce9-994d-bd0f48cd3956.png)








