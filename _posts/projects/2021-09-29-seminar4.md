---
layout: post
title: Seminar4 
description: |
tags:
  - projects
use_math : true
comments : true
author: Udayeon

published: true
---

논문 작성을 위한 주제잡기 과정

# 목차
1. 자율주행 기술동향
2. 연구방향
3. 실험
4. 결과
5. 고찰


# 1. 자율주행차량 기술동향
* * *
자율주행 기술이란 차량이 스스로 주변 환경을 인지하고 상황에 맞는 판단에 따라 적절히 제어하여 목적지까지 안전하게 도달하는 기술을 말한다. 사람의 눈은 매우 직관적이라 인지하고 판단을 내리는 데에
아주 짧은 시간만이 필요하지만 기계는 그렇지 않다. 대상의 형태,색,명도 등 다양한 시각적 정보를 알고리즘에 따라 처리한 후에야 비로소 사물의 정체를 알게 된다. 따라서 자율주행 차량이 사람의 눈처럼 
빠르고 정확하게 객체를 인식하는 것이 자율주행기술의 과업이라 할 수 있겠다. 이를 위해, 사람의 눈과 같은 기능을 해주는 다양한 센서들을 차량에 부착한다. 센서의 예로는 카메라, 라이다, 레이더가 있다.
각각의 센서는 장단점이 다르므로 죄근 센서퓨전이라 하는 기술을 통해 이들을 다양하게 조합해 사용하기도 한다.   
앞서, 자율주행기술을 크게 인지,판단,제어 세 가지로 나눈단 것을 언급했다. 가장 먼저 '인지(Perception)'에 대해 다루고자 한다. 설명한대로 기계의 인지 능력은 사람의 눈처럼 직관적이지 않으므로
사물을 인식하기 위해선 상대적으로 오랜 시간이 필요하고 그 정확도도 떨어지는 실정이다. 이런 문제점을 보완하는 것이 인지 기술의 핵심이라 할 수 있겠다. 객체 인식을 위한 다양한 알고리즘이 존재하겠지만
단연 독보적으로 정확한 알고리즘은 딥러닝으로 훈련시킨 알고리즘이다. 딥러닝이란 인간이 뇌에서 신경세포를 시용하는 것과 유사한 방식으로 알고리즘을 
활용하는 기술을 말한다. 예시 데이터를 통해 컴퓨터가 학습하고 새로운 데이터가 들어와도 이에 대처할 수 있는 능력을 갖게 되는 것이다.
딥러닝 기반의 다양한 객체인식 알고리즘이 있고 이를 구현하고자 한다.


# 2.Sensor Fusion
* * *
Matlab sensor fusion 구현하기

## 2.1. Extended Object Tracking of Highway Vehicles with Radar and Camera
* * *
### (1) 개요
이 예제는 ego vehicle이 고속도로에서 주변차량의 어떻게 추적하는지를 보여준다. 차량은 확장된 객체로, 그 크기가 다수의 resolution cell에
걸쳐있게 된다. 결과적으로, 센서는 한 번의 스캔으로 이 객체의 검출을 보고한다. 이 예제에서, 다른 extendee object tracking 기술을 이용해
고속도로의 차량을 추적하고 tracking성능을 검증할 수 있다.
   
기존의 tracking 접근법(multiObjectTracker/trackerGNN, trakcerJPDA/multi-hypothesis tracking)을 통해 추적된 객체는 센서 스캔 당
하나의 detection을 반환하는 것으로 가정한다. 고해상도 radar와 같이 더 나은 resolution을 갖는 센서의 개발로, 센서들은 일반적으로
객체에 대한 한 번의 detection보다 더 많이 반환하게 되었다. 예를 들어, 아래의 이미지는 Radar의 여러 resolution cell에 걸쳐있는 한 차량에
대한 multiple detection을 보여준다. 이런 경우, 객체 추적에 사용된 기술은 **extended object tracking**으로 알려져있다.
![image](https://user-images.githubusercontent.com/69246778/137067319-ac2bb3d5-6ef0-43ae-a851-33781765e69f.png)
<고해상도 센서를 이용한 스캔 한번으로 객체에 대한 여러 detection을 return함>
   
고해상도 센서 이용의 가장 중요한 이점은 객체의 치수 및 방향과 같은 물체에 대한 더 많은 정보를 얻을 수 있다는 것이다. 이 추가 정보들은
탐지 확률을 높이고 오탐확률을 줄여줄 수 있다.   
   
확장된 객체는 기존의 tracker에 새로운 과업을 제시한다. 왜냐하면 기존의 tracker들은 센서하나당 객체하나, 그리고 객체 하나당 한 번의 탐지를
가정하기 때문이다. 몇몇 경우에, 객체 하나 당 단일 탐지를 실행하는 기존 tracker를 위해 센서 데이터를 cluster할 수 있다. 그러나, 그렇게
하게되면, 고해상도 센서를 사용하는 이유가 없다.   
   
반면, extended object tracker는 객체 당 여러 탐지를 다룬다. 게다가, 이 tracker는 위치나 속도 같은 운동 상태뿐 아니라 물체의 차원과
방향도 추정할 수 있다. 예를 들어, 다음의 tracker들을 이용해 ego vehicle 주변 차량을 추적한다고 하자.
* 기존의 tracker : multi object tracker ( point target model이용)
* GGIW-PHD tracker : Gamma Gaussian Inverse Wishart PHD, GGIW필터를 사용한 PHD tracker
* GM-PHD tracker : Gaussian Mixture PHD, (rectangular filter 이용)

tracker의 성능 평가는 **trackErrorMetrics**와 **trackAssignmentMetrics**를 사용한다. 이는 tracker의 모든 효율 측정 결과를 평가한다. 
**trackOSPAMetric(Optimal SubPattern Assignment Metric)** 을 이용해 점수로써 tracker의 성능을 평가한다.

### (2)시나리오 만들기
이 예제에는 ego vehicle과 4대의 다른 차량이 있다. ego vehicle은 중앙 lane에 있고 같은 차선에 앞뒤로 차량 한대씩, 오른쪽 차선 앞에 트럭 한대, 그리고
왼쪽 차선으로 ego vehicle을 추월하는 차량이 한대 있다.   
ego vehicle에 부착된 센서는 6개의 radar, 2개의 vision센서로 차량의 360 시야를 모두 커버한다. 센서에는 일부 overlap과 센서 간의 
coverage gap(커버하지 못하는 틈)이 존재한다. 차량의 앞과 뒤에 long-range radar센서와 vision센서가 부착되어 있고, 차량 측면에는
short-range radar센서가 부착되어 있다. short-range radar는 각각 90도 범위를 다룬다. 측면 센서 중 하나는 차량 중앙부터 후면까지 커버할 수 있고
다른 하나는 차량 중앙부터 전방까지 커버가능하다.
![image](https://user-images.githubusercontent.com/69246778/137069595-739812fe-2003-4b70-b061-46b8fc672268.png)
<long-range radar>
  
### (3)tracker성능 평가
* trackErrorMetrics : 객체의 위치,속도,치수,방향을 얼마나 정확히 추정하느냐에 따라 tracker의 성능평가
* helperExtendedTargetError : ground truth와 추적된 target같의 오차를 정의
* trackAssignmentMetrics : 잘못된 추적이나 중복된 추적의 수를 계산
* helperExtendedTargetDistance : truth 객체와 추적된 target간의 distance를 계산.distance metrics를 위치, 속도, 치수, yaw의 거리 합으로 정의

### (4)Point Object Tracker (Multi Object Tracker)
**multiObjectTracker**는 센서당 한 객체의 단일 탐지를 가정한다. 또한, 전역적으로 가장 **nearesr-neighbor**방식을 사용하여 detection과 tracking
을 연관짓는다. 그리고 한 번의 스캔으로 센서에 의해 모든 개체를 최대 한 번 탐지할 수 있다고 가정한다(--> 최대 한번? 한번 이상으로 중복 탐지는 안된다는것?)
이 경우, 시뮬레이션 된 radar센서는 객체 당 다수의 탐지가 충분히 가능한 고해상도를 가지고 있다. 만약 이러한 detection이 cluster되지 않는 경우,
tracker는 객체 당 여러 개의 추적을 발생한다. 클러스터링은 클러스터 당 한번의 detection만을 반환한다.또한, 클러스터링은 두 물체가 가까이에 있는 경우
이를 구별하기 어렵게 만든다. 
![image](https://user-images.githubusercontent.com/69246778/137071914-18bc7233-13b5-47b1-af3a-c85888b56382.png)
<Nearest-Neighbor>

