---
layout: post
title: VisualSLAM
description: |
  [K-mooc 자율주행자동차기술(국민대학교) 강의](http://www.kmooc.kr/courses/course-v1:KMUk+CK-KMUK_02+2021_1/course/)
  
tags:
  - autonomous
use_math : true
comments : true
author: Udayeon
published: true
---

Visual SLAM

* 1. Visual SLAM 기술 개요
  * 1.1 Visual SLAM
  * 1.2 특징 검출과 특징 매칭
  * 1.3 카메라 자세 추정
  * 1.4 특징점 탐색 실습
* 2. VisualSLAM 기술 기초
  * 2.1 초기 카메라 추정
  * 2.2 카메라 트래킹
  * 2.3 이중 시점 분석 실습
* 3. VisualSLAM 기술 심화
  * 3.1 국소 지도 확장과 전역 지도 정합
  * 3.2 루프 결합과 카메라 위치 재조정
  * 3.3 카메라 위치 재조정 실습
 
 
# 1. Visual SLAM 기술 개요
* * *

## 1.1 Visual SLAM
* * *

### 1.1.1 SLAM기술이란?
동시적 위치추적 및 지도 작성기술.   
미지의 영역에 대해 환경지도를 작성하는 **Mapping**과 작성된 지도상에서 위치를 추정하는 **Localization**을 동시에 해결하는 알고리즘.
자기 위치가 어딘지 알아야 새롭게 탐사한 영역에 대한 정보를 현재 지도에 정확히 붙일 수 있음.

### 1.1.2. Visual SLAM 이란?
**시각 데이터**를 이용해 동시적 위치추적 및 지도 작성을 하는 알고리즘.

### 1.1.3. Visual SLAM 응용분야
* 자율주행 자동차   
인지 기술로 작동   
EX ) 구글의 웨이모   
지붕에 달린 라이다가 시각 센서로 작동하여 지도 정보가 없는 곳을 지나면 알고리즘으로 지도를 작성(Mapping)하고 이미 지도를 확보한 곳에서는
현재 자동차가 어디에 있는지를 파악함(Localization).   
   
* 증강 현실   
모바일 폰이나 HMD에 달린 카메라가 주변 환경에 대한 시각 데이터를 수집하고 Visual SLAM으로 환경지도와 현재 위치를 얻어낸다. 
그리고 가상 물체를 지도상에 배치해 실제로 있는 것과 같이 표현.   
   
* 로봇청소기   
로봇청소기를 처음 사서 집을 한 번 훑어보게 하면 Visual SLAM이 지도를 작성함. 정확한 지도를 위해 위치 추정도 동시에 진행.   
      
### 1.1.4. 로봇청소기로 알 수 있는 자율주행의 문제   
* Kidnapping   
전원이 꺼진 로봇청소기를 사람이 직접 들어 다른 방에 옮겨 놓고 전원을 켜는 경우.   

* 위치 재조정   
Kidnapping된 로봇이 전원이 꺼지기 전 마지막으로 알고 있던 위치는 잘못된 정보라는 것을 인지하고 지도에서 자신이 자리잡고 있는 새 위치를 빠르게 인식하는 것.   
   
* 업데이트    
자신이 기존에 알고 있던 지도를 현재 상황에 맞에 업데이트하는 것.   
   
**자율주행의 경우** 시동이 꺼지기 전 자동차의 위치와 시동이 다시 켜진 위치가 다르거나 도로의 지형이 바뀌거나 지도에는 없는 큰 
장애물이 나타나는 경우, 자율주행 자동차는 기존의 지도 정보를 업데이트해 가며 안전히 운행해야 함.   

### 1.1.5. Visual SLAM System Component   
* Visual Sensor   
(일반적으로 카메라)이미지 데이터를 수집.   
   
* 특징점 검출과 매칭   
**특징점 검출**은 VisualSLAM System이 영상을 손쉽게 다루기 위해 필요한 영상처리 과정. 한 장을 빠르고 효과적으로 처리하기 위해 
이미지로부터 특징이 되는 지점을 검출하는 과정이고, **특징점 매칭**은  서로 다른 두 영상에서 검출한 특징점 사이의 대응관계를 구하는 과정. 
특징점 검출과 매칭으로 처리된 영상들이 VisualSLAM System에서 활용됨.   
   
**VisualSLAM에서의 활용**    
  - 카메라 자세추정 : 같은 장면을 서로다른 시점에서 바라본 이미지를 활용하여 두 카메라의 상대적 위치를 추정. 추후, 이미지 두 장으로부터 
   삼각측량을 이용해 3차원 위치를 추정할 수 있음 **(3차원 지도 작성)**   
  - 카메라 트래킹 : 카메라가 돌아다니면서 이미지를 얻을 때 이미지의 특징점으로 카메라가 지도 내에 어디 있는지 위치를 추정.   
  - 국소적 지도관리 : 카메라가 돌아다니면서 경계에 다다를 때 지도를 넓히는 것.   
  - 전역 지도관리 : 전체 지형을 둘러볼 때 위상적으로 문제가 없도록 연결고리 형태로 지도 구성.


## 1.2. 특징 검출과 매칭
* * *

### 1.2.1. 특징 검출과 매칭이란?
카메라가 찍은 이미지에 대한 특징을 검출하고 서로 다른 이미지에서 검출된 특징간의 매칭을 계산하는 과정. SLAM을 돌리기 위한 가장
기본적인 데이터 전처리 과정. 

### 1.2.2. 특징 검출
예를 들어, 3차원 장면을 카메라로 찍게되면 너비x높이의 개수만큼 픽셀로 구성된 이미지를 얻게되는데, 이는 **SLAM이 처리하기에 너무 방대함.** 
따라서, SLAM시스템에서 이미지 전체에 대한 데이터를 넘겨주기 보다는 **특징 검출을 통해 이미지를 특징점 위주로 줄인 후** 해당 지점만 SLAM System에 넘겨줌. 그럼 **SLAM System이 가볍고 빠르게(효율적으로)** 돌아갈 수 있음.   

#### 1.2.2.A. 특징점
그렇다면 어떤 점이 특징점이 될 수 있을까?   
**주변의 다른 지점과 비교했을 때 고유하게 인식될 수 있는 지점**을 특징점이라고 함. 보통 특징점은, 육안으로 봤을 때의 모서리 지점(corner point)
에 해당함.   

#### 1.2.2.B. 특징 검출 알고리즘
**Harris corner detection 알고리즘**   
해리스가 제안한 자가유사도 기반의 알고리즘.
1. 다음과 같이 주어진 이미지에 빨간색, 노란색, 녹색으로 표시된 3지점을 살펴봄.   
![image](https://user-images.githubusercontent.com/69246778/126956046-d5156937-f841-447a-8894-ec1034d6dfb3.png)   
   
2. 먼저 빨간색 지점(작은 빨간 박스)을 살펴봄. 빨간색 지점 중심으로 이미지 조각인 패치를 생성(커다란 빨간박스).   
빨간색 패치 내의 한 픽셀을 새로운 지점(주변 지점)으로 삼고 그 지점에 대한 새로운 패치를 생성(커다란 회색박스).   
이때 빨간색 패치와 회색 패치를 비교해 보면 둘이 같아서 구분이 안됨.   
빨간색 패치 내의 다른 지점들도 이런 방식으로 보면 비슷해서 구분 안됨. 따라서 빨간색 지점은 특징점이 될 수 없음.   
![image](https://user-images.githubusercontent.com/69246778/126956090-5c2dea15-f6e3-4a31-9cc7-e20e8f1be531.png)   
   
3. 노란색 지점을 중심으로 패치를 잡고 위와 같은 방식으로 진행함. 만약 edge방향으로 주변 지점을 잡으면 회색패치와 구별이 안됨.   
노란색도 특징점이 될 수 없음.   
![image](https://user-images.githubusercontent.com/69246778/126956123-348a6c47-3473-4639-b950-ba3dfb952e29.png)   

4. 녹색 지점을 중심으로 패치를 잡고 다시 반복. 어떤 지점을 잡아도 주변 지점과 확실하게 구별됨. **특징점**   
![image](https://user-images.githubusercontent.com/69246778/126956171-c0e65828-c76f-47c8-bd24-f091f2275272.png)   
   
**FAST corner detector**, **ORB corner detector**등 다양한 알고리즘이 있음.

### 1.2.3. 특징 매칭
두 이미지에서 따로 뽑은 특징점이 실제로 같은 지점이라고 생각된다면 서로 짝을 지어줌. 특징 매칭은 **두 이미지 사이의 관계 계산**에 쓰임. 
예를 들어, 이미지에 찍힌 내용이 다른 이미지에도 들어 있어 **두 영상이 유사한지 여부**를 측정하거나, **카메라 자세 추정**에 활용.

#### 1.2.3.A. 특징 매칭의 과정
1. 특징묘사 과정   
특징점을 비교 가능한 자료 형태, **특징 묘사자**로 바꿔줌. 좋은 특징 묘사자는 사람의 눈으로 봤을 때 동일한 지점이라고 생각하는 경우,
비슷한 특징 묘사자를 가지도록 하고 아닌 경우는 다른 특징 묘사자를 가지도록 하는 것. 즉, 어떤 지점이 확대되거나 축소되거나 회전되거나
어파인 또는 투사변환 된다든지 조명 조건이 살짝 달라진 환경에서도 거의 비슷한 특징 묘사자를 만들어내야 함. 

2. 특징매칭 과정
특징 묘사결과를 활용하여 유사도가 높은 특징쌍끼리 매칭해줌.



##### [HMD](https://terms.naver.com/entry.naver?docId=3586641&cid=59277&categoryId=59278)
Head Mounted Display(=Face Mounted Display), 안경처럼 착용하고 사용하는 모니터.   
![image](https://user-images.githubusercontent.com/69246778/126945688-4e7cd9fb-8667-4994-be55-bac3893eced5.png)

##### [Affine transform](https://wiserloner.tistory.com/849)
영상을 구성하는 픽셀의 배치 구조를 변경함으로써 영상 모양을 변경하는 geometric transform의 일종으로 영상의 평행이동, 확대 및 축소,
회전 등의 조합으로 만들 수 있는 기하학적 변환을 통칭한다. 픽셀의 위치를 일정한 규칙에 따라 옮김으로써 영상 변화를 이루는 것.

##### [투사 변환](https://wordrow.kr/%EC%9D%98%EB%AF%B8/%ED%88%AC%EC%82%AC%20%EB%B3%80%ED%99%98/)
3차원 도형을 2차원 평면 위에 표시하기 위한 투영 변환 중 하나. 
