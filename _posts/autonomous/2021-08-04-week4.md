---
layout: post
title: Week 4. AI와 Machine Learning
description: |
  자율주행과 인공지능, 기계학습 일반, 기계학습 방법론
hide_image: true
tags:
  - autonomous
published: true
---
Week 4. AI와 Machine Learning

- 1. 자율주행과 인공지능
  - 1.1. AI
  - 1.2. Machine Learning
  - 1.3. Data
  - 1.4. 지도학습(Supervised Learning)
  - 1.5. 비지도학습(Unsupervised Learning)
  - 1.6. 강화학습(Reinforcement Learning)
  - 1.7. 준지도학습(Semi-Supervised Learning)
- 2. 기계학습 일반
- 3. 기계학습 방법론


# 1. 자율주행과 인공지능
* * *
자율주행을 위해선 **인지, 판단, 제어** 3가지의 기능이 안전하게 이루어져야 한다.
그러나 컴퓨터가 마치 사람처럼 주행 환경을 정확히 인지하고, 위험을 판단해 적절한 제어를 하는 것은 어렵다.
따라서, **인공지능 기술을 이용하여 이를 보완한다면 더욱 안전한 자율주행이 가능할 것이다.**

## 1.1. what is AI?
Artificial Intelligence,인간의 지능과 유사한 특성을 가진 복잡한 컴퓨터를 말한다. 
1956년 미국 다트머스 대학의 존 맥카시(John MaCathy)교수가 인공지능을 주제로 첫 학술대회를 개최하며 이곳에서 
**인공지능**이란 용어를 처음 사용했다. 기계가 인간이 풀지 못하는 어렵고 복잡한 문제들을 해결했지만 반대로, 
인간에겐 쉬운 문제지만 기계는 해결하지 못하는 문제도 있다. 예를 들어, **감정 판단, 음성 인식, 번역**등은 
인간에게 직관적이므로 쉽게 해결할 수 있지만 기계로 해결하기는 매우 어렵다.   
      
인간처럼 의식, 감정, 정신을 가진 인공지능을 **강한 인공지능**이라 하는데 이는 우리가 영화에서나 볼 수 있고 주로 다루게 될 
것은 **약한 인공지능**이다. 이는 특정 문제를 해결하기 위해 개발된 것으로 이성적 업무를 연구하고 완수하기 위한 인공지능이다.
자율주행차량에 사용되는 인공지능이나 알파고 같은 것들이 그 예시임.   


## 1.2. Machine Learning
> Tom Michell
" 기계가 특정 과제에 대한 다양한 **경험**을 통해 성능(Perfomance)을 개선하는 알고리즘을 연구하는 것." 
   
> Authur Samuel 
" 명백하게 프로그래밍하지 않고, 컴퓨터에게 **학습할 수 있는 능력**을 주는 연구 분야"

컴퓨터에 지식을 추가시키고 이 추가된 지식에 기반해 컴퓨터가 판단을 내리도록 하는 전통적인 방식을 
**지식기반방식(Knowledge-based system)** 이라 한다. 그러나 컴퓨터에게 지식을 무한히 추가하는 것은 불가능하므로 기계학습
으로의 대전환이 일어났다.   
   
기계학습은 마치 어린아이가 시행착오를 겪으며 성장하는 것처럼 기계가 학습을 통해 향상되는 것을 말한다. 기계를 학습 시키기
위해서는 **훈련데이터(Training Data)** 와 **시험데이터(Test Data)** 가 필요하다. Training data로 기계를 학습시킨 다음
학습이 잘 되었는지를 Test data로 평가한다. Test data는 미리 알 수가 없으므로 Training data를 단순히 암기하는 식의 학습이 
아니라 Training data의 일반적인 패턴을 학습해야 한다. 그래야 새로 주어진 Test data에서도 고성능을 발휘할 수 있을 것이다.
이처럼 일반적인 패턴을 학습해 높은 성능을 발휘하는 능력을 **일반화 능력(Generalization)** 이라 한다.    
   
그런데, 기계가 학습을 과하게 철저히 하게 되면 Training data에는 아주 잘 적용되지만 외려 새로운 Test data에는 잘 적용되지 
않는 현상이 발생할 수 있다. 이를 **Over-fitting**이라 한다.   
   

## 1.3. Data
과학기술의 발전은 **데이터를 수집하고 그 데이터를 기반으로 모델을 정립한 후 예측하는 것**을 통해 이루어진다. 
따라서 잘못된 모델을 정립한다면 데이터를 설명하지 못하게 될 것이고 제대로 된 모델로 데이터를 설명한다면 새로운 이론이 
탄생하게 될 것이다. 이처럼 데이터는 모델 정립의 기반이 되므로 매우 중요하다. **Database**는 여러 사람이 공유할 목적으로 
체계화해 통합, 관리하는 데이터의 집합을 말하는데 이것이 기계학습의 Input요소이므로 그 품질이 매우 중요하다.   
자율주행 관련 공개 DB로는 칼스루 공대의 KITTI(각족 센서 데이터 공개), UC버클리의 BDD100k등이 있음.


## 1.4. 지도학습(Supervised Learning)
**특징 벡터(데이터의 특징을 나타낸 벡터) X와 목표값(특징벡터에 대한 정답,Label) Y가 모두 주어진 상황**에서의 
기계학습을 말한다. 예를 들어, 어린아이에게 사과 사진을 보여주며 이것이 사과라는 것을 알려주는 것과 같다. 
지도학습은 **분류문제**와 **회귀문제**로 구분할 수 있다.   
   
먼저, **분류문제**는 정답이 이산값인 경우로써 '사람이다. 나무다. 자동차다' 처럼 딱딱 떨어지는 답(Label)을 갖는다. 
이때, 정답들이 '사람, 나무, 자동차,...' 처럼 카테고리화 될 수 있으므로 목표값 Y는 Class형태를 보인다.   
**회귀문제**는 정답이 연속적인 값인 경우다. 예를들어, 자율주행자동차가 위치를 추정하고자 한다면 위치에 대한 목표값이
좌표로 주어질 것이다. 

## 1.5. 비지도학습(Unsupervised Learning)
지도학습이 X와 Y가 모두 주어지는 학습인데 반해, 비지도학습은 **특징벡터 X는 주어지지만 목표값 Y는 주어지지 않는 상황**에서의 
학습이다. 여러 사진을 보여주면서 'A사진과 B사진이 비슷하니 같은 물체일 것이다.' 또는 'A사진과 B사진은 빨간색이 많이 보인
다.'등으로 정답은 모른 상태로 특징만을 학습한다. 비지도학습으로 수행할 수 있는 문제는, 
**군집화(Clustering), 밀도추정, 특징공간변환(차원축소)** 등이 있다.   
   
**군집화**는 서로 비슷한 것끼리 묶는 과정을 말한다. 사진을 관리하는 시스템(비슷한 것끼리 묶어 놓기)이나 
영상분할(Segmentation)등에 사용된다. 군집화의 종류에는 **Hard clustering(일반군집화)**과 **Fuzzy clustering**가 있다.
전자는, 데이터가 하나의 군집에만 소속되는 것이고, 후자는 데이터가 여러 군집에 소속될 수 있다.   
   
**밀도추정(Density estimation)** 은 데이터와 변수의 관계를 파악하는 방법이다. 데이터(EX:모의고사성적)로 변수(EX:수능성적)
가 가질 수 있는 모든 값의 밀도(확률)를 추정하는 것.   
   
**차원축소(Dimension reduction)** 은 고차원의 데이터 정보를 손실을 최소화하면서 저차원으로 변환하는 것. 고차원 데이터의
경우 관측 Step이 기하급수적으로 증가하거나 그것을 표현하기 위한 데이터 양이 기하급수적으로 증가하면서 메모리 문제가 발생할
수 있다. 이를 **차원의 저주**라 하는데, 이런 문제를 해결하기 위해 데이터의 의미를 제대로 표현하는 특징만을 추려내는
**차원축소**가 필요하다.


## 1.6. [강화학습(Reinforcement Learning)](https://opentutorials.org/course/4548/28949)
목표값 Y가 주어지지만 직접적으로 주어지진 않아 지도학습과는 다르다. 지도학습이 배움을 통해 실력을 키우는 것이라면 
강화학습은 일단 해보면서 실력을 키워가는 것이다. 선택의 결과가 자신에게 유리하면 상을 받고 아니라면 벌을 받는다. 
게임과 비교하면, 게임의 승패에 따라 보상 또는 벌칙을 부여하여 보상의 합이 최대화 되는 방향으로 학습하는 것이다.
즉, 어떤 환경 안에 정의된 agent가 현재의 상태를 인식하여 선택 가능한 행동들 중 보상을 최대화하는 행동 혹은 행동 순서를 
선택한다. 

## 1.7. 준지도학습(Semi-Supervised Learning)
지도학습과 비지도학습의 중간으로, 일부는 X와 Y를 가지지만 나머지는 X만 가진 상황에서의 학습. 이 둘을 통합하여 활용한다. 
정답을 갖고 있는 데이터와 정답이 없는 데이터를 통합해서 활용한다.




# 2. 기계학습 일반
* * *
기계학습은 **예측**문제를 해결하며 예측에는 **회귀**와 **분류**가 있다. 어떤 실수값을 예측하는 것이 **회귀(Regression)** 이고, 어떤 부류인지
예측하는 것이 **분류(Classification)** 이다.

## 2.1. 지도학습 - 예측회귀문제
![image](https://user-images.githubusercontent.com/69246778/128805812-14f34b7d-1e61-470e-8d85-b7b16ac1009a.png)   
특징과 목표값을 이용해 추세를 예측하는 문제이다. 위의 그림에 있는 4개의 점은 training set의 요소들로 사례 또는 Sample이라 하는데, 이를 이용해
추세를 예측한다. (임의의 시간이 주어졌을 때 이동체의 위치같은거 예측)   

이 예시 그림은 눈대중으로 보면 직선을 이루므로 **선형모델**을 선택한다. 
![image](https://user-images.githubusercontent.com/69246778/128805991-bbf8b33e-a83a-4ef2-8591-78b2da200761.png)   
이 선형모델로 학습을 마치면 매개변수 (w,b)를 갖게된다. 이 매개변수가 최적이라야 일반화능력이 좋다.
즉, 매개변수 (w,b)의 전체 집합을 Θ라고 한다면 **좋은 Θ를 어떻게 학습할 것인지(일반화 능력을 어떻게 올릴지)가 관건**

### 2.1.1 좋은 Θ value를 구하려면?
일단 training을 잘 하는게 기본임. training을 잘하고 있는지를 판단하는 척도가 되는 게 **목적함수(Objective function)=
비용함수(Cost function)=손실함수(Loss function)**. 이 함수들은 Θ에 대한 예측치가 정답과 얼마나 차이가 있는지 나타내는 함수.
대표적으로 평균제곱오차함수(MSE, Mean Squared Error)가 있음.   
![image](https://user-images.githubusercontent.com/69246778/128807831-8211bb51-0e40-4905-92cc-8e97550bebc6.png)   
n개의 data point에 대해서 예측치와 정답 사이의 차이를 제곱한 다음 평균낸 것   
   
![image](https://user-images.githubusercontent.com/69246778/128808224-25a47b9e-ce6e-45e7-9ed4-435af8a583c9.png)
즉, Θ를 변수로 한 목적함수 J를 최소화 해주는 argument Θ를 선택하는 것.

#### 2.1.1.A. 경사하강법(Gradient Descent Method)
J를 Minimization하기 위해, 함수를 편미분하고 값의 반대 방향으로 이동해 최소값을 찾는 방법.   
![image](https://user-images.githubusercontent.com/69246778/128809551-e5648053-7108-4c69-a0d7-e06b03bc77a5.png)   
두 개의 변수 x0, x1에 대한 함수 f를 미분하면 다음과 같이 표현됨.
![image](https://user-images.githubusercontent.com/69246778/128809668-e61146ab-7fa7-476a-b308-5d9a0837b992.png)   
즉, 화살표의 반대 방향으로 움직이면 최소값에 도달할 수 있음.   
식으로 나타내면 다음과 같음. Parameter의 업데이트 과정을 보여줌. 여기서 η는 학습률(Learning rate)로, 이 학습률만큼씩 미분의 반대방향으로
움직이는 것.   
![image](https://user-images.githubusercontent.com/69246778/128814854-5d6dfdab-af18-46cf-ace8-2d6e6cd5308a.png)   
![image](https://user-images.githubusercontent.com/69246778/128814487-e8bd43bb-a647-4f94-80eb-ba6d0871084c.png)    

**NOTE📝** 
```
Learning rate가 크면 더 빠르게 최소값에 다다를텐데 이때 어떤 문제가 발생할지?
```

### 2.1.2. 선형모델의 한계
![image](https://user-images.githubusercontent.com/69246778/128815260-6443de2d-8be9-4316-aa2b-aa87b0993058.png)
실제 세계는 선형이 아니며 Noise가 섞이므로 비선형 모델이 필요함.

## 2.2. 지도학습 - 비선형회귀문제
![image](https://user-images.githubusercontent.com/69246778/128815470-1ba0671f-6104-4172-8cb2-9e2d37549660.png)

### 2.2.1 Under-fitting, Over-fitting
#### 2.2.1.A. Under-fitting
모델의 용량이 작아 오차가 클 수 밖에 없는 현상. 

#### 2.2.1.B. Over-fitting
Training에 매우 충실해 Training set에 대한 오차는 감소하지만 새로운 데이터 예측 시에는 오차가 증가함 (=일반화 능력 저하)


### 2.2.2. 일반화능력향상 - Bias, Variance
Over-fitting 해결에 사용. bias와 Variance가 trade off 관계이므로 둘 모두를 고려해 적당한 모델을 선정하는 것이 일반화능력을 높여줌

#### 2.2.2.A. Bias
어떤 Training set를 여러번 다르게 수집하여 1차~12차 모델에 적용했을 때 그 예측치가 매번 이루는 **오차의 평균**.
당연히 bias가 적을수록 오차가 적다는 거니까 좋음. 단순한 1차 모델같은 경우에는 bias가 클 수 밖에 없음. 12차는 상대적으로 굉장히
작게 나올 것. 근데 작다고 무조건 좋은 건 아님. 분산도 함께 고려되어야 함.

#### 2.2.2.B. Variance
Training data가 조금만 바뀌어도 모델의 파라미터가 많이 바뀌므로 예측치 역시 바뀌게 되는 것. variance가 크면, 다양항 data에 유연하게 대응. 
Bias와 Trade off관계에 있음. bias가 크면 분산은 작고, bias가 작으면 분산은 커짐.
![image](https://user-images.githubusercontent.com/69246778/128816529-c893baaf-a930-41f1-b14e-0f998e3df24e.png)
![image](https://user-images.githubusercontent.com/69246778/128816548-2a9b8f38-60fb-4c97-8d44-54ae1c605550.png)

### 2.2.3. 일반화능력 향상 - Validation
마치 수능의 모의고사 같은거. Validation set로 알고리즘을 검증해보는 것

#### 2.2.3.A. 교차검증(Cross Validation)
비용 문제로 별도의 Validation set가 없는 경우에 Training Data의 일부를 Validation set로 활용하여 학습과 평가 과정을 여러번 반복한 후
평균 사용

### 2.2.4. 일반화능력 향상 - data 수집
데이터를 더 많이 수집할수록 일반화 능력이 향상됨.
![image](https://user-images.githubusercontent.com/69246778/128818865-5e9cc4fe-5ced-49e6-9e1e-197ddb009e7c.png)   
예를들어, 12차 모델을 가지고 parameter를 tuning하면 이상한 경향을 배우게 될 수 있음. 전형적인 over-fitting임. 
이때, (c)처럼 data 자체가 많으면 실제 system이 가지고 있는 특성을 더 많이 보여줄 수 있으므로 더 정확한 모델을 학습할 수 있음

**NOTE📝** 
```
너무 과한 비선형이라 굉장히 집요(?)하므로 경향성에 벗어난 data point까지 학습해버릴 수 있음
```

근데, 데이터를 수집하는 건 비용이 들고 불가능한 경우도 있음. 그럴 때 사용하는 방법이 다음과 같은 것들.

#### 2.2.4.A. 데이터 확대(Data augmentation)
인위적으로 데이터를 생성해내는 것. Training set의 sample들을 이용해 조금씩 변화(회전, Warping)시키면서 우리가 관찰할 수 있을만한
데이터 생성.
![image](https://user-images.githubusercontent.com/69246778/128819611-be17edcb-9c03-4e39-ad7a-1084aaab0253.png)
예를 들어 이렇게 변형된 손글씨들을 학습하면 다양한 손글씨를 잘 일반화하게 됨.

### 2.2.5. 일반화능력 향상 - Regularization(규제)
어떤 모델의 weight가 너무 크지 않도록 규제하는 것. 예를들어 12차 모델의 경우 data point가 많이 없을 때 굉장히 큰 weight를 가짐.
weight가 크다는 것은 over-fitting을 유발하므로 목적함수를 조정해 이를 규제하면 일반화 능력이 향상됨.
![image](https://user-images.githubusercontent.com/69246778/128820363-57a9f094-1bc6-4d35-bed9-a40d4f1cce07.png)   

# 3. Machine Learning 방법론
* * *
지도학습(supervised Learning)과 비지도학습(Unsupervised Learning)
![image](https://user-images.githubusercontent.com/69246778/128821889-cb4c31fe-c13a-432d-b90d-5b34d40b5673.png)

- 3.1 지도학습
  - 3.1.1. 지도학습 - Support Vector Machine (분류문제)
  - 3.1.2. 지도학습 - Kernel-SVM
- 3.2. 비지도학습
  - 3.2.1. Clustering
     - 3.2.1.A. K-means clustering algorithm
  - 3.2.2. 차원축소(Dimensionality Reduction)
    - 3.2.2.A. 주성분 분석(PCA, Principal component analysis)
    - 3.2.2.B. Autoencoder
    - 3.2.2.C. Sparse Auto encoder (SAE)
    - 3.2.2.D. Denoising Auto encoder (DAE)

## 3.1. 지도학습

## 3.1.1. 지도학습 - Support Vector Machine (분류문제)
딥러닝 이전, 1990년대에 많이 쓰였던 기술. 요즘은 딥러닝하고 SVM을 같이 쓰기도 함. 여백의 크기를 최대화하는 최적화 문제를 풀어 
직선의 방정식을 구함.   
![image](https://user-images.githubusercontent.com/69246778/128822707-fd39b2a0-13c3-47b3-8153-9e736e70bfc3.png)   
1번 : 잘못된 분류를 하게될 것, 검정하고 흰색을 구분 못함   
2번,3번 : 분류는 잘 하게될 것, 2보다 3을 선택.   
   
![image](https://user-images.githubusercontent.com/69246778/128823195-c54e6c3b-c765-436e-b0e6-3309592a080a.png)
2S가 여백임. 이 여백을 최대화시키는 최적화 문제를 풀면 됨.

## 3.1.2. 지도학습 - Kernel-SVM
비선형 SVM. Input space의 데이터를 선형분류가 가능한 고차원 공간(Feature Space)로 이동 후 두 범주를 분류하는 초평면 찾는 것인데 
이 공간변환에 시간이 오래 소요됨. 따라서 고차원 mapping과 그 안에서 필요한 계산을 동시에 수행함.

## 3.2. 비지도학습
어떤 목표치를 맞추는 것은 불가능하지만 데이터에 숨겨진 특징이나 구조를 발견할 수 있음

**NOTE📝** 
```
정답이 주어지지 않고 data의 특성만 보니까
```

### 3.2.1. Clustering
![image](https://user-images.githubusercontent.com/69246778/128953483-51e5792b-323f-4b10-a509-7a9d5b29e093.png)

#### 3.2.1.A. K-means clustering algorithm
![image](https://user-images.githubusercontent.com/69246778/128953672-cddeacfc-300f-4c51-8782-651889340b87.png)
군집 중심정 k개가 조금씩 이동하는데, 그 과정을 반복하다가 더 이상 군집의 중심이 이동하지 않게 되면 멈춤.

### 3.2.2. 차원축소(Dimensionality Reduction)
만약 이미지 데이터를 보는데, 이 이미지의 크기가 100x100이면 만 개나 되는 데이터 point가 생성됨. 이 10000차원의 데이터를 모두 표현
하는 것보다 10개의 차원으로 축소하면서 그 데이터의 특징을 거의 그대로 포함할 수 있다면 그렇게 하는게 좋음. 왜냐면 성능도 좋아지고 계산속도도
빨라지기 때문. 지도학습의 전처리 과정으로도 많이 사용됨.

#### 3.2.2.A. 주성분 분석(PCA, Principal component analysis)
주어진 데이터의 분포를 나타내기에 가장 적합한 축들을 찾는 방법. 즉, 분산이 가장 크게 되는 축을 찾는 것.(분산이 클수록 정보 손실이 적음)
2차원을 1차원으로 줄여서 데이터를 표현하려면?
1. x축으로 축소하면, 첫번째 그래프
2. y축으로 축소하면, 두번째 그래프
3. 비스듬히 축소하면, 세번째 그래프 : 이 경우 4개의 점들이 모두 다른 점으로 기술됨. 또한, 각 점들의 분산이 최대가 되는 경우임
![image](https://user-images.githubusercontent.com/69246778/128954310-a3abe698-5438-41f5-8a34-6829cc11f3ba.png)

#### 3.2.2.B. Auto encoder
인공신경망으로 차원을 축소하는 방법. 어떤 특징벡터 x를 input으로 받아 동일하거나 유사한 벡터x'을 출력하는 신경망.
중간에 하나의 Hidden layer를 두는데 이 Hidden layer의 차원m을 input의 차원인 d보다 적게 만듦.
우리가 표현하고자 하는 벡터x를 d개의 차원이 아닌 m개의 차원으로도 충분히 표현할 수 있게됨. 그니까 x가 단순히 x'으로 복사되는 것이 아니라
m차원의 feature space로 변환되는 것

#### 3.2.2.C. Sparse Auto encoder (SAE)
Autoencoder 구조상에 있는 weight들을 0으로 강제하는 기법. 적은 수의 가중치만 가지고도 input벡터를 설명할 수 있으므로
m이 d보다 큰 상황에서도 x가 가진 핵심 feature를 추출할 수 있음. 

#### 3.2.2.D. Denoising Auto encoder (DAE)
일부러 noise를 추가한 다음에 그런 상황에서도 원본을 복원하도록 학습하는 원리






