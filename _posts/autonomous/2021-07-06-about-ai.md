---
layout: post
title: About AI
description: |
  AI와 Machine Learning에 대한 간단한 정리
hide_image: true
tags:
  - autonomous
published: true
---

# 1. 자율주행과 AI
* * *
자율주행을 위해선 **인지, 판단, 제어** 3가지의 기능이 안전하게 이루어져야 한다.
그러나 컴퓨터가 마치 사람처럼 주행 환경을 정확히 인지하고, 위험을 판단해 적절한 제어를 하는 것은 어렵다.
따라서, **인공지능 기술을 이용하여 이를 보완한다면 더욱 안전한 자율주행이 가능할 것이다.**

- 1.1. what is AI(Artificial Intelligence) 
- 1.2. Type of AI
- 1.3. Machine Learning
  - 1.3.1. 일반화능력(Generalization)
  - 1.3.2. 과적응(Over-fitting)
  - 1.3.3. 지식기반방식(Knowledge-based system)
  - 1.3.4. Data
- 1.4. Type of Machine Learning
  - 1.4.1. 지도학습(Supervised Learning)
    - 1.4.1.A. 분류문제
    - 1.4.1.B. 회귀 문제 
  - 1.4.2. 비지도학습(Unsupervised Learning)
    - 1.4.2.A. 군집화(Clustering)
    - 1.4.2.B. 밀도추정
    - 1.4.2.C. 특징 공간 변환(차원축소)
  - 1.4.3. 강화학습(Reinforcement Learning)
  - 1.4.4. 준지도학습(Semi-Supervised Learning)

## 1.1. what is AI(Artificial Intelligence)
인간의 지능과 유사한 특성을 가진 복잡한 컴퓨터. 
   
   
**NOTE📝** 
```
'인간의 지능'이 어떤 특성을 갖는지?
```

## 1.2. Type of AI
- **강한 인공지능** : 인간과 같은 의식, 감정, 정신을 가진 기계로 우리가 영화에서 볼 수 있는 인공지능 
   
- **약한 인공지능** : 특정 문제를 해결하기 위한 개발된 것으로 이성적 업무를 연구, 완수하기 위한 인공지능. 예를 들어, 알파고나 음성인식 장치, 영상 인식장치 같은거. **자율주행에 사용되는 인공지능** 

## 1.3. Machine Learning
> Tom Michell
" 기계가 특정 과제에 대한 다양한 **경험**을 통해 성능(Perfomance)을 개선하는 알고리즘을 연구하는 것." 
   
> Authur Samuel 
" 명백하게 프로그래밍하지 않고, 컴퓨터에게 **학습할 수 있는 능력**을 주는 연구 분야"
   
기계학습은 마치 어린아이가 시행착오를 겪으며 성장하는 것처럼 기계가 학습을 통해 향상되는 것.   
기계학습을 위해선 **훈련데이터(Training Data)** 와 **시험데이터(Test Data)** 가 필요.
   
|Training data|Test data|
|:------------|:--------|
|기계 학습 시 사용|학습 완료된 알고리즘을 테스트 할 때 사용(이걸로 기계의 성능 평가)|

### 1.3.1. 일반화능력(Generalization)
Test data는 미리 알 수가 없으므로 Training data를 단순히 암기하는 식의 학습이 아니라 Training data의 일반적인 패턴을 학습해야
새로 주어진 Test data에서도 고성능을 발휘할 수 있을 것. 이러한 능력을 말함.

### 1.3.2. 과적응(Over-fitting)
기계가 학습을 과하게 철저히 하는 바람에 훈련 데이터에는 아주 잘 적용되지만 외려, 새로운 시험 데이터에는 잘 적용되지 않는 현상.

### 1.3.3. 지식기반방식(Knowledge-based system)
지식을 컴퓨터에 추가 시키는 방식. 과거에는 이렇게 추가된 지식에 기반해 컴퓨터가 판단을 내리도록 했음. 예를 들어, 단추를 구별하는 알고리즘을
만들고자 할 때 기계학습의 경우 다양한 모양의 단추를 보여주며 일반적인 패턴을 학습하여 어떤 모습의 단추가 나와도 판단할 수 있는 반면 
지식기반 장식은 모든 모양의 단추를 일일히 추가해주어야 하므로 추가되지 않은 새로운 단추가 나오면 컴퓨터는 이를 인식하지 못함.
지식을 무한히 추가하는 것은 불가능 하므로 지식기반 방식에서 기계학습 방식으로의 대전환이 일어났음.

### 1.3.4. Data
과학기술의 발전은 **데이터를 수집하고 그 데이터를 기반으로 모델을 정립한 후 예측하는 것**을 통해 이루어진다. 
그러나, 만약 잘못된 모델을 정립한다면 데이터를 설명하지 못하게 될 것이고 또는 제대로 된 모델로 데이터를 설명한다면 새로운 이론이 탄생하게 
될 것. 이처럼 데이터는 모델 정립의 기반이 되므로 매우 중요. **Database**는 여러 사람이 공유할 목적으로 체계화해 통합, 관리하는 데이터의 
집합. 이것이 기계학습의 Input요소이므로 그 품질이 매우 중요.
자율주행 관련 공개 DB로는 칼스루 공대의 KITTI(각족 센서 데이터 공개), UC버클리의 BDD100k등이 있음.


## 1.4. Type of Machine Learning

### 1.4.1. 지도학습(Supervised Learning)
특징 벡터(데이터의 특징을 나타낸 벡터) X와 목표값(특징벡터에 대한 정답,Label) Y가 모두 주어진 상황에서의 학습. 
특징 예를 들어, 어린아이에게 사과 사진을 보여주며 이것이 사과라는 것을 알려주는 것과 같은 학습방법.
지도학습은 **분류문제**와 **회귀문제**로 구분할 수 있음.

#### 1.4.1.A. 분류문제
정답이 이산 값인 경우. '사람이다, 나무다, 자동차다' 처럼 딱딱 떨어지는 답(Label)을 갖는 것. 
이 때 '사람이다, 나무다, 자동차다.'라는 식으로 정답이 카테고리화 될 수 있으므로 목표값 Y는 카테고리(class)형태를 보인다.

#### 1.4.1.B. 회귀 문제 
정답이 연속적인 값인 경우. 자율주행자동차가 위치를 추정한다면 위치에 대한 값이 좌표(목표값)로 주어질 것이다. 
목표값 Y는 실수의 형태를 보임.

### 1.4.2. 비지도학습(Unsupervised Learning)
특징벡터 X는 주어지지만 목표값 Y는 주어지지 않는 상황에서의 학습. 여러 사진을 보여주면서 'A사진과 B사진이 비슷하니 같은 물체일 것이다.' 또는 'A사진과 B사진은 빨간색이 많이 보인다.'등으로 정답은 모른 상태로 특징만을 학습한다.

#### 1.4.2.A. 군집화(Clustering)
서로 비슷한 것끼리 묶는 과정. 예를 들어, 인지 작업에 있어서 차량의 크기를 어느정도 짐작해야 Detection이 가능하므로 크기에 따른 Clustering이 필요.

#### 1.4.2.B. 밀도추정
어떠한 특징을 갖는 분포를 추정

#### 1.4.2.C. 특징 공간 변환(차원축소)
자율주행 차량의 데이터들의 특징 차원이 너무 많을 경우 저차원의 특징들로 추려내는 작업.

### 1.4.3. 강화학습(Reinforcement Learning)
목표값 Y가 주어지지만 직접적으로 주어지진 않아 지도학습과는 다른 형태. 바둑을 학습하는 경우를 예로 들면, 바둑을 둘 때에는 모르다가 게임이 
끝나고 나서 '이게 좋은 수 였구나'를 깨닫게 하는 것. 게임의 승패에 따라 보상 또는 벌칙을 부여하여 보상의 합이 최대화 되는 방향으로 학습.
즉, 어떤 환경 안에 정의된 agent가 현재의 상태를 인식하여 선택 가능한 행동들 중 보상을 최대화하는 행동 혹은 행동 순서를 선택.

### 1.4.4. 준지도학습(Semi-Supervised Learning)
지도학습과 비지도학습의 중간으로, 일부는 X와 Y를 가지지만 나머지는 X만 가진 상황에서의 학습. 이 둘을 통합하여 활용한다. X만 가지는 데이터는
예를 들어, 블랙박스 영상과 같은 것이다. 블박 영상 자체가 X라면, 그 영상 속의 물체가 사물인지 보행자인지 등에 대한 정답은 Y가 된다.


# 2. Machine Learning 
* * *
기계학습의 개념

- 2.1. 지도학습 - 선형회귀문제
  - 2.1.1. Training data의 오차를 줄이기
    - 2.1.1.A. 경사하강법(Gradient Descent Method)
  - 2.1.2. 선형모델의 한계
- 2.2. 지도학습 - 비선형회귀문제
  - 2.2.1 Under-fitting, Over-fitting
    - 2.2.1.A. Under-fitting
    - 2.2.1.B. Over-fitting
  - 2.2.2. 일반화능력향상 - Bias, Variance
     - 2.2.2.A. Bias
     - 2.2.2.B. Variance
  - 2.2.3. 일반화능력 향상 - Validation
    - 2.2.3.A. 교차검증(Cross Validation) 
  - 2.2.4. 일반화능력 향상 - data 수집
    - 2.2.4.A. 데이터 확대(Data augmentation)
  - 2.2.5. 일반화능력 향상 - Regularization(규제)


## 2.1. 지도학습 - 선형회귀문제
![image](https://user-images.githubusercontent.com/69246778/128805812-14f34b7d-1e61-470e-8d85-b7b16ac1009a.png)   

특징과 목표값을 이용해 추세를 예측하는 것. 위의 그림처럼 4개의 training set로 추세를 예측함. (임의의 시간이 주어지면 이동체의 위치는?)   
눈대중으로 보면 직선을 이루므로 **선형모델** 선택.   
![image](https://user-images.githubusercontent.com/69246778/128805991-bbf8b33e-a83a-4ef2-8591-78b2da200761.png)   
이 선형모델로 학습을 마치면 최적의 매개변수 (w,b)를 얻게 됨. 일반화 능력이 좋을수록 최적임.
이 매개변수 (w,b)의 전체 집합을 Θ라고 했을 때, **좋은 Θ를 어떻게 학습할 것인지(일반화 능력을 어떻게 올릴지)가 관건**

### 2.1.1 좋은 Θ value를 구하려면?
일단 training을 잘 하는게 기본임. training을 잘하고 있는지를 판단하는 척도가 되는 게 **목적함수(Objective function)=
비용함수(Cost function)=손실함수(Loss function)**. 이 함수들은 Θ에 대한 예측치가 정답과 얼마나 차이가 있는지 나타내는 함수.
대표적으로 평균제곱오차함수(MSE, Mean Squared Error)가 있음.   
![image](https://user-images.githubusercontent.com/69246778/128807831-8211bb51-0e40-4905-92cc-8e97550bebc6.png)   
n개의 data point에 대해서 예측치와 정답 사이의 차이를 제곱한 다음 평균낸 것   
   
![image](https://user-images.githubusercontent.com/69246778/128808224-25a47b9e-ce6e-45e7-9ed4-435af8a583c9.png)
즉, Θ를 변수로 한 목적함수 J를 최소화 해주는 argument Θ를 선택하는 것.

#### 2.1.1.A. 경사하강법(Gradient Descent Method)
J를 Minimization하기 위해, 함수를 편미분하고 값의 반대 방향으로 이동해 최소값을 찾는 방법.   
![image](https://user-images.githubusercontent.com/69246778/128809551-e5648053-7108-4c69-a0d7-e06b03bc77a5.png)   
두 개의 변수 x0, x1에 대한 함수 f를 미분하면 다음과 같이 표현됨.
![image](https://user-images.githubusercontent.com/69246778/128809668-e61146ab-7fa7-476a-b308-5d9a0837b992.png)   
즉, 화살표의 반대 방향으로 움직이면 최소값에 도달할 수 있음.   
식으로 나타내면 다음과 같음. Parameter의 업데이트 과정을 보여줌. 여기서 η는 학습률(Learning rate)로, 이 학습률만큼씩 미분의 반대방향으로
움직이는 것.   
![image](https://user-images.githubusercontent.com/69246778/128814854-5d6dfdab-af18-46cf-ace8-2d6e6cd5308a.png)   
![image](https://user-images.githubusercontent.com/69246778/128814487-e8bd43bb-a647-4f94-80eb-ba6d0871084c.png)    

**NOTE📝** 
```
Learning rate가 크면 더 빠르게 최소값에 다다를텐데 이때 어떤 문제가 발생할지?
```

### 2.1.2. 선형모델의 한계
![image](https://user-images.githubusercontent.com/69246778/128815260-6443de2d-8be9-4316-aa2b-aa87b0993058.png)
실제 세계는 선형이 아니며 Noise가 섞이므로 비선형 모델이 필요함.

## 2.2. 지도학습 - 비선형회귀문제
![image](https://user-images.githubusercontent.com/69246778/128815470-1ba0671f-6104-4172-8cb2-9e2d37549660.png)

### 2.2.1 Under-fitting, Over-fitting
#### 2.2.1.A. Under-fitting
모델의 용량이 작아 오차가 클 수 밖에 없는 현상. 

#### 2.2.1.B. Over-fitting
Training에 매우 충실해 Training set에 대한 오차는 감소하지만 새로운 데이터 예측 시에는 오차가 증가함 (=일반화 능력 저하)


### 2.2.2. 일반화능력향상 - Bias, Variance
Over-fitting 해결에 사용. bias와 Variance가 trade off 관계이므로 둘 모두를 고려해 적당한 모델을 선정하는 것이 일반화능력을 높여줌

#### 2.2.2.A. Bias
어떤 Training set를 여러번 다르게 수집하여 1차~12차 모델에 적용했을 때 그 예측치가 매번 이루는 **오차의 평균**.
당연히 bias가 적을수록 오차가 적다는 거니까 좋음. 단순한 1차 모델같은 경우에는 bias가 클 수 밖에 없음. 12차는 상대적으로 굉장히
작게 나올 것. 근데 작다고 무조건 좋은 건 아님. 분산도 함께 고려되어야 함.

#### 2.2.2.B. Variance
Training data가 조금만 바뀌어도 모델의 파라미터가 많이 바뀌므로 예측치 역시 바뀌게 되는 것. variance가 크면, 다양항 data에 유연하게 대응. 
Bias와 Trade off관계에 있음. bias가 크면 분산은 작고, bias가 작으면 분산은 커짐.
![image](https://user-images.githubusercontent.com/69246778/128816529-c893baaf-a930-41f1-b14e-0f998e3df24e.png)
![image](https://user-images.githubusercontent.com/69246778/128816548-2a9b8f38-60fb-4c97-8d44-54ae1c605550.png)

### 2.2.3. 일반화능력 향상 - Validation
마치 수능의 모의고사 같은거. Validation set로 알고리즘을 검증해보는 것

#### 2.2.3.A. 교차검증(Cross Validation)
비용 문제로 별도의 Validation set가 없는 경우에 Training Data의 일부를 Validation set로 활용하여 학습과 평가 과정을 여러번 반복한 후
평균 사용

### 2.2.4. 일반화능력 향상 - data 수집
데이터를 더 많이 수집할수록 일반화 능력이 향상됨.
![image](https://user-images.githubusercontent.com/69246778/128818865-5e9cc4fe-5ced-49e6-9e1e-197ddb009e7c.png)   
예를들어, 12차 모델을 가지고 parameter를 tuning하면 이상한 경향을 배우게 될 수 있음. 전형적인 over-fitting임. 
이때, (c)처럼 data 자체가 많으면 실제 system이 가지고 있는 특성을 더 많이 보여줄 수 있으므로 더 정확한 모델을 학습할 수 있음

**NOTE📝** 
```
너무 과한 비선형이라 굉장히 집요(?)하므로 경향성에 벗어난 data point까지 학습해버릴 수 있음
```

근데, 데이터를 수집하는 건 비용이 들고 불가능한 경우도 있음. 그럴 때 사용하는 방법이 다음과 같은 것들.

#### 2.2.4.A. 데이터 확대(Data augmentation)
인위적으로 데이터를 생성해내는 것. Training set의 sample들을 이용해 조금씩 변화(회전, Warping)시키면서 우리가 관찰할 수 있을만한
데이터 생성.
![image](https://user-images.githubusercontent.com/69246778/128819611-be17edcb-9c03-4e39-ad7a-1084aaab0253.png)
예를 들어 이렇게 변형된 손글씨들을 학습하면 다양한 손글씨를 잘 일반화하게 됨.

### 2.2.5. 일반화능력 향상 - Regularization(규제)
어떤 모델의 weight가 너무 크지 않도록 규제하는 것. 예를들어 12차 모델의 경우 data point가 많이 없을 때 굉장히 큰 weight를 가짐.
weight가 크다는 것은 over-fitting을 유발하므로 목적함수를 조정해 이를 규제하면 일반화 능력이 향상됨.
![image](https://user-images.githubusercontent.com/69246778/128820363-57a9f094-1bc6-4d35-bed9-a40d4f1cce07.png)   

# 3. Machine Learning 방법론
* * *
지도학습(supervised Learning)과 비지도학습(Unsupervised Learning)
![image](https://user-images.githubusercontent.com/69246778/128821889-cb4c31fe-c13a-432d-b90d-5b34d40b5673.png)

- 3.1 지도학습
  - 3.1.1. 지도학습 - Support Vector Machine (분류문제)
  - 3.1.2. 지도학습 - Kernel-SVM
- 3.2. 비지도학습
  - 3.2.1. Clustering
     - 3.2.1.A. K-means clustering algorithm
  - 3.2.2. 차원축소(Dimensionality Reduction)
    - 3.2.2.A. 주성분 분석(PCA, Principal component analysis)
    - 3.2.2.B. Autoencoder
    - 3.2.2.C. Sparse Auto encoder (SAE)
    - 3.2.2.D. Denoising Auto encoder (DAE)

## 3.1. 지도학습

## 3.1.1. 지도학습 - Support Vector Machine (분류문제)
딥러닝 이전, 1990년대에 많이 쓰였던 기술. 요즘은 딥러닝하고 SVM을 같이 쓰기도 함. 여백의 크기를 최대화하는 최적화 문제를 풀어 
직선의 방정식을 구함.   
![image](https://user-images.githubusercontent.com/69246778/128822707-fd39b2a0-13c3-47b3-8153-9e736e70bfc3.png)   
1번 : 잘못된 분류를 하게될 것, 검정하고 흰색을 구분 못함   
2번,3번 : 분류는 잘 하게될 것, 2보다 3을 선택.   
   
![image](https://user-images.githubusercontent.com/69246778/128823195-c54e6c3b-c765-436e-b0e6-3309592a080a.png)
2S가 여백임. 이 여백을 최대화시키는 최적화 문제를 풀면 됨.

## 3.1.2. 지도학습 - Kernel-SVM
비선형 SVM. Input space의 데이터를 선형분류가 가능한 고차원 공간(Feature Space)로 이동 후 두 범주를 분류하는 초평면 찾는 것인데 
이 공간변환에 시간이 오래 소요됨. 따라서 고차원 mapping과 그 안에서 필요한 계산을 동시에 수행함.

## 3.2. 비지도학습
어떤 목표치를 맞추는 것은 불가능하지만 데이터에 숨겨진 특징이나 구조를 발견할 수 있음

**NOTE📝** 
```
정답이 주어지지 않고 data의 특성만 보니까
```

### 3.2.1. Clustering
![image](https://user-images.githubusercontent.com/69246778/128953483-51e5792b-323f-4b10-a509-7a9d5b29e093.png)

#### 3.2.1.A. K-means clustering algorithm
![image](https://user-images.githubusercontent.com/69246778/128953672-cddeacfc-300f-4c51-8782-651889340b87.png)
군집 중심정 k개가 조금씩 이동하는데, 그 과정을 반복하다가 더 이상 군집의 중심이 이동하지 않게 되면 멈춤.

### 3.2.2. 차원축소(Dimensionality Reduction)
만약 이미지 데이터를 보는데, 이 이미지의 크기가 100x100이면 만 개나 되는 데이터 point가 생성됨. 이 10000차원의 데이터를 모두 표현
하는 것보다 10개의 차원으로 축소하면서 그 데이터의 특징을 거의 그대로 포함할 수 있다면 그렇게 하는게 좋음. 왜냐면 성능도 좋아지고 계산속도도
빨라지기 때문. 지도학습의 전처리 과정으로도 많이 사용됨.

#### 3.2.2.A. 주성분 분석(PCA, Principal component analysis)
주어진 데이터의 분포를 나타내기에 가장 적합한 축들을 찾는 방법. 즉, 분산이 가장 크게 되는 축을 찾는 것.(분산이 클수록 정보 손실이 적음)
2차원을 1차원으로 줄여서 데이터를 표현하려면?
1. x축으로 축소하면, 첫번째 그래프
2. y축으로 축소하면, 두번째 그래프
3. 비스듬히 축소하면, 세번째 그래프 : 이 경우 4개의 점들이 모두 다른 점으로 기술됨. 또한, 각 점들의 분산이 최대가 되는 경우임
![image](https://user-images.githubusercontent.com/69246778/128954310-a3abe698-5438-41f5-8a34-6829cc11f3ba.png)

#### 3.2.2.B. Auto encoder
인공신경망으로 차원을 축소하는 방법. 어떤 특징벡터 x를 input으로 받아 동일하거나 유사한 벡터x'을 출력하는 신경망.
중간에 하나의 Hidden layer를 두는데 이 Hidden layer의 차원m을 input의 차원인 d보다 적게 만듦.
우리가 표현하고자 하는 벡터x를 d개의 차원이 아닌 m개의 차원으로도 충분히 표현할 수 있게됨. 그니까 x가 단순히 x'으로 복사되는 것이 아니라
m차원의 feature space로 변환되는 것

#### 3.2.2.C. Sparse Auto encoder (SAE)
Autoencoder 구조상에 있는 weight들을 0으로 강제하는 기법. 적은 수의 가중치만 가지고도 input벡터를 설명할 수 있으므로
m이 d보다 큰 상황에서도 x가 가진 핵심 feature를 추출할 수 있음. 

#### 3.2.2.D. Denoising Auto encoder (DAE)
일부러 noise를 추가한 다음에 그런 상황에서도 원본을 복원하도록 학습하는 원리






